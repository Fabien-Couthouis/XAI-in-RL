{"episode_reward_max": NaN, "episode_reward_min": NaN, "episode_reward_mean": NaN, "episode_len_mean": NaN, "episodes_this_iter": 0, "policy_reward_mean": {}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 1000, "num_steps_sampled": 1000, "wait_time_ms": 7.626, "apply_time_ms": 7.859, "dispatch_time_ms": 25.012, "learner": {}}, "timesteps_this_iter": 1000, "done": false, "timesteps_total": 1000, "episodes_total": 0, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-39-40", "timestamp": 1606318780, "training_iteration": 1, "time_this_iter_s": 51.685291051864624, "time_total_s": 51.685291051864624, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def37da0>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def62048>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 51.685291051864624, "timesteps_since_restore": 1000, "iterations_since_restore": 1}
{"episode_reward_max": NaN, "episode_reward_min": NaN, "episode_reward_mean": NaN, "episode_len_mean": NaN, "episodes_this_iter": 0, "policy_reward_mean": {}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 3000, "num_steps_sampled": 3000, "wait_time_ms": 8.177, "apply_time_ms": 8.871, "dispatch_time_ms": 26.37, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 3000, "episodes_total": 0, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-39-47", "timestamp": 1606318787, "training_iteration": 2, "time_this_iter_s": 7.672362327575684, "time_total_s": 59.35765337944031, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def62198>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def629e8>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 59.35765337944031, "timesteps_since_restore": 3000, "iterations_since_restore": 2}
{"episode_reward_max": NaN, "episode_reward_min": NaN, "episode_reward_mean": NaN, "episode_len_mean": NaN, "episodes_this_iter": 0, "policy_reward_mean": {}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 5000, "num_steps_sampled": 5000, "wait_time_ms": 8.999, "apply_time_ms": 8.031, "dispatch_time_ms": 25.521, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 5000, "episodes_total": 0, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-39-55", "timestamp": 1606318795, "training_iteration": 3, "time_this_iter_s": 7.5748069286346436, "time_total_s": 66.93246030807495, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def73320>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def73710>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 66.93246030807495, "timesteps_since_restore": 5000, "iterations_since_restore": 3}
{"episode_reward_max": -423.0, "episode_reward_min": -1254.0, "episode_reward_mean": -831.3333333333334, "episode_len_mean": 1000.0, "episodes_this_iter": 6, "policy_reward_mean": {"agent-0": -175.0, "agent-1": -192.0, "agent-2": -159.83333333333334, "agent-3": -143.0, "agent-4": -161.5}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 7000, "num_steps_sampled": 7000, "wait_time_ms": 61.028, "apply_time_ms": 7.094, "dispatch_time_ms": 27.125, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 7000, "episodes_total": 6, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-40-03", "timestamp": 1606318803, "training_iteration": 4, "time_this_iter_s": 8.103461980819702, "time_total_s": 75.03592228889465, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def62e80>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def62b38>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 75.03592228889465, "timesteps_since_restore": 7000, "iterations_since_restore": 4}
{"episode_reward_max": -423.0, "episode_reward_min": -1254.0, "episode_reward_mean": -831.3333333333334, "episode_len_mean": 1000.0, "episodes_this_iter": 0, "policy_reward_mean": {"agent-0": -175.0, "agent-1": -192.0, "agent-2": -159.83333333333334, "agent-3": -143.0, "agent-4": -161.5}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 9000, "num_steps_sampled": 9000, "wait_time_ms": 8.51, "apply_time_ms": 6.728, "dispatch_time_ms": 26.03, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 9000, "episodes_total": 6, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-40-11", "timestamp": 1606318811, "training_iteration": 5, "time_this_iter_s": 7.627112865447998, "time_total_s": 82.66303515434265, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def735c0>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def73278>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 82.66303515434265, "timesteps_since_restore": 9000, "iterations_since_restore": 5}
{"episode_reward_max": -423.0, "episode_reward_min": -1254.0, "episode_reward_mean": -831.3333333333334, "episode_len_mean": 1000.0, "episodes_this_iter": 0, "policy_reward_mean": {"agent-0": -175.0, "agent-1": -192.0, "agent-2": -159.83333333333334, "agent-3": -143.0, "agent-4": -161.5}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 11000, "num_steps_sampled": 11000, "wait_time_ms": 10.473, "apply_time_ms": 7.343, "dispatch_time_ms": 27.077, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 11000, "episodes_total": 6, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-40-18", "timestamp": 1606318818, "training_iteration": 6, "time_this_iter_s": 7.67081618309021, "time_total_s": 90.33385133743286, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def629e8>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def73b38>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 90.33385133743286, "timesteps_since_restore": 11000, "iterations_since_restore": 6}
{"episode_reward_max": 312.0, "episode_reward_min": -1254.0, "episode_reward_mean": -371.3333333333333, "episode_len_mean": 1000.0, "episodes_this_iter": 6, "policy_reward_mean": {"agent-0": -64.16666666666667, "agent-1": -86.16666666666667, "agent-2": -79.66666666666667, "agent-3": -60.25, "agent-4": -81.08333333333333}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 13000, "num_steps_sampled": 13000, "wait_time_ms": 6.831, "apply_time_ms": 7.701, "dispatch_time_ms": 26.626, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 13000, "episodes_total": 12, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-40-26", "timestamp": 1606318826, "training_iteration": 7, "time_this_iter_s": 7.558242082595825, "time_total_s": 97.89209342002869, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def73908>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def733c8>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 97.89209342002869, "timesteps_since_restore": 13000, "iterations_since_restore": 7}
{"episode_reward_max": 312.0, "episode_reward_min": -1254.0, "episode_reward_mean": -371.3333333333333, "episode_len_mean": 1000.0, "episodes_this_iter": 0, "policy_reward_mean": {"agent-0": -64.16666666666667, "agent-1": -86.16666666666667, "agent-2": -79.66666666666667, "agent-3": -60.25, "agent-4": -81.08333333333333}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 15000, "num_steps_sampled": 15000, "wait_time_ms": 7.941, "apply_time_ms": 8.127, "dispatch_time_ms": 28.042, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 15000, "episodes_total": 12, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-40-34", "timestamp": 1606318834, "training_iteration": 8, "time_this_iter_s": 7.65077018737793, "time_total_s": 105.54286360740662, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def62b38>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def73e10>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 105.54286360740662, "timesteps_since_restore": 15000, "iterations_since_restore": 8}
{"episode_reward_max": 312.0, "episode_reward_min": -1254.0, "episode_reward_mean": -371.3333333333333, "episode_len_mean": 1000.0, "episodes_this_iter": 0, "policy_reward_mean": {"agent-0": -64.16666666666667, "agent-1": -86.16666666666667, "agent-2": -79.66666666666667, "agent-3": -60.25, "agent-4": -81.08333333333333}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 17000, "num_steps_sampled": 17000, "wait_time_ms": 9.504, "apply_time_ms": 8.863, "dispatch_time_ms": 25.672, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 17000, "episodes_total": 12, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-40-41", "timestamp": 1606318841, "training_iteration": 9, "time_this_iter_s": 7.586335182189941, "time_total_s": 113.12919878959656, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def73390>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def73048>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 113.12919878959656, "timesteps_since_restore": 17000, "iterations_since_restore": 9}
{"episode_reward_max": 501.0, "episode_reward_min": -1254.0, "episode_reward_mean": -124.66666666666667, "episode_len_mean": 1000.0, "episodes_this_iter": 6, "policy_reward_mean": {"agent-0": -3.2777777777777777, "agent-1": -32.0, "agent-2": -44.77777777777778, "agent-3": -20.666666666666668, "agent-4": -23.944444444444443}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 19000, "num_steps_sampled": 19000, "wait_time_ms": 7.404, "apply_time_ms": 6.838, "dispatch_time_ms": 28.293, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 19000, "episodes_total": 18, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-40-49", "timestamp": 1606318849, "training_iteration": 10, "time_this_iter_s": 7.49588942527771, "time_total_s": 120.62508821487427, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def628d0>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def62cf8>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 120.62508821487427, "timesteps_since_restore": 19000, "iterations_since_restore": 10}
{"episode_reward_max": 501.0, "episode_reward_min": -1254.0, "episode_reward_mean": -124.66666666666667, "episode_len_mean": 1000.0, "episodes_this_iter": 0, "policy_reward_mean": {"agent-0": -3.2777777777777777, "agent-1": -32.0, "agent-2": -44.77777777777778, "agent-3": -20.666666666666668, "agent-4": -23.944444444444443}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 21000, "num_steps_sampled": 21000, "wait_time_ms": 6.567, "apply_time_ms": 8.225, "dispatch_time_ms": 27.121, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 21000, "episodes_total": 18, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-40-56", "timestamp": 1606318856, "training_iteration": 11, "time_this_iter_s": 7.585878849029541, "time_total_s": 128.2109670639038, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def73828>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def736a0>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 128.2109670639038, "timesteps_since_restore": 21000, "iterations_since_restore": 11}
{"episode_reward_max": 501.0, "episode_reward_min": -1254.0, "episode_reward_mean": -124.66666666666667, "episode_len_mean": 1000.0, "episodes_this_iter": 0, "policy_reward_mean": {"agent-0": -3.2777777777777777, "agent-1": -32.0, "agent-2": -44.77777777777778, "agent-3": -20.666666666666668, "agent-4": -23.944444444444443}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 23000, "num_steps_sampled": 23000, "wait_time_ms": 7.546, "apply_time_ms": 8.24, "dispatch_time_ms": 27.802, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 23000, "episodes_total": 18, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-41-04", "timestamp": 1606318864, "training_iteration": 12, "time_this_iter_s": 7.595825910568237, "time_total_s": 135.80679297447205, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def626a0>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def73c88>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 135.80679297447205, "timesteps_since_restore": 23000, "iterations_since_restore": 12}
{"episode_reward_max": 528.0, "episode_reward_min": -1254.0, "episode_reward_mean": 15.125, "episode_len_mean": 1000.0, "episodes_this_iter": 6, "policy_reward_mean": {"agent-0": 24.666666666666668, "agent-1": -7.875, "agent-2": -12.541666666666666, "agent-3": 4.375, "agent-4": 6.5}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 25000, "num_steps_sampled": 25000, "wait_time_ms": 6.393, "apply_time_ms": 6.831, "dispatch_time_ms": 23.162, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 25000, "episodes_total": 24, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-41-11", "timestamp": 1606318871, "training_iteration": 13, "time_this_iter_s": 7.071021556854248, "time_total_s": 142.8778145313263, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def73be0>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def62ef0>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 142.8778145313263, "timesteps_since_restore": 25000, "iterations_since_restore": 13}
{"episode_reward_max": 528.0, "episode_reward_min": -1254.0, "episode_reward_mean": 15.125, "episode_len_mean": 1000.0, "episodes_this_iter": 0, "policy_reward_mean": {"agent-0": 24.666666666666668, "agent-1": -7.875, "agent-2": -12.541666666666666, "agent-3": 4.375, "agent-4": 6.5}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 27000, "num_steps_sampled": 27000, "wait_time_ms": 7.5, "apply_time_ms": 7.39, "dispatch_time_ms": 23.277, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 27000, "episodes_total": 24, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-41-18", "timestamp": 1606318878, "training_iteration": 14, "time_this_iter_s": 7.067154407501221, "time_total_s": 149.94496893882751, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def73c88>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def739b0>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 149.94496893882751, "timesteps_since_restore": 27000, "iterations_since_restore": 14}
{"episode_reward_max": 574.0, "episode_reward_min": -1254.0, "episode_reward_mean": 37.48, "episode_len_mean": 1000.0, "episodes_this_iter": 1, "policy_reward_mean": {"agent-0": 28.2, "agent-1": -3.2, "agent-2": -6.44, "agent-3": 8.04, "agent-4": 10.88}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 29000, "num_steps_sampled": 29000, "wait_time_ms": 7.996, "apply_time_ms": 8.123, "dispatch_time_ms": 25.074, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 29000, "episodes_total": 25, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-41-25", "timestamp": 1606318885, "training_iteration": 15, "time_this_iter_s": 7.173619508743286, "time_total_s": 157.1185884475708, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def732e8>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def73a90>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 157.1185884475708, "timesteps_since_restore": 29000, "iterations_since_restore": 15}
{"episode_reward_max": 574.0, "episode_reward_min": -1254.0, "episode_reward_mean": 108.86666666666666, "episode_len_mean": 1000.0, "episodes_this_iter": 5, "policy_reward_mean": {"agent-0": 39.833333333333336, "agent-1": 12.633333333333333, "agent-2": 7.1, "agent-3": 20.466666666666665, "agent-4": 28.833333333333332}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 31000, "num_steps_sampled": 31000, "wait_time_ms": 5.685, "apply_time_ms": 6.766, "dispatch_time_ms": 24.038, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 31000, "episodes_total": 30, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-41-33", "timestamp": 1606318893, "training_iteration": 16, "time_this_iter_s": 7.117578029632568, "time_total_s": 164.23616647720337, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def62b00>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def626a0>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 164.23616647720337, "timesteps_since_restore": 31000, "iterations_since_restore": 16}
{"episode_reward_max": 574.0, "episode_reward_min": -1254.0, "episode_reward_mean": 108.86666666666666, "episode_len_mean": 1000.0, "episodes_this_iter": 0, "policy_reward_mean": {"agent-0": 39.833333333333336, "agent-1": 12.633333333333333, "agent-2": 7.1, "agent-3": 20.466666666666665, "agent-4": 28.833333333333332}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 33000, "num_steps_sampled": 33000, "wait_time_ms": 5.908, "apply_time_ms": 7.58, "dispatch_time_ms": 25.807, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 33000, "episodes_total": 30, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-41-40", "timestamp": 1606318900, "training_iteration": 17, "time_this_iter_s": 7.015620946884155, "time_total_s": 171.25178742408752, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def73dd8>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def73208>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 171.25178742408752, "timesteps_since_restore": 33000, "iterations_since_restore": 17}
{"episode_reward_max": 574.0, "episode_reward_min": -1254.0, "episode_reward_mean": 133.09375, "episode_len_mean": 1000.0, "episodes_this_iter": 2, "policy_reward_mean": {"agent-0": 43.875, "agent-1": 16.6875, "agent-2": 14.09375, "agent-3": 24.03125, "agent-4": 34.40625}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 35000, "num_steps_sampled": 35000, "wait_time_ms": 6.444, "apply_time_ms": 7.521, "dispatch_time_ms": 24.914, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 35000, "episodes_total": 32, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-41-47", "timestamp": 1606318907, "training_iteration": 18, "time_this_iter_s": 7.145331621170044, "time_total_s": 178.39711904525757, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def62588>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def8dbe0>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 178.39711904525757, "timesteps_since_restore": 35000, "iterations_since_restore": 18}
{"episode_reward_max": 574.0, "episode_reward_min": -1254.0, "episode_reward_mean": 174.41666666666666, "episode_len_mean": 1000.0, "episodes_this_iter": 4, "policy_reward_mean": {"agent-0": 51.083333333333336, "agent-1": 27.055555555555557, "agent-2": 22.944444444444443, "agent-3": 33.75, "agent-4": 39.583333333333336}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 37000, "num_steps_sampled": 37000, "wait_time_ms": 4.859, "apply_time_ms": 8.27, "dispatch_time_ms": 22.667, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 37000, "episodes_total": 36, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-41-54", "timestamp": 1606318914, "training_iteration": 19, "time_this_iter_s": 7.016162872314453, "time_total_s": 185.41328191757202, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def73be0>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def8d1d0>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 185.41328191757202, "timesteps_since_restore": 37000, "iterations_since_restore": 19}
{"episode_reward_max": 574.0, "episode_reward_min": -1254.0, "episode_reward_mean": 174.41666666666666, "episode_len_mean": 1000.0, "episodes_this_iter": 0, "policy_reward_mean": {"agent-0": 51.083333333333336, "agent-1": 27.055555555555557, "agent-2": 22.944444444444443, "agent-3": 33.75, "agent-4": 39.583333333333336}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 39000, "num_steps_sampled": 39000, "wait_time_ms": 7.947, "apply_time_ms": 8.672, "dispatch_time_ms": 23.382, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 39000, "episodes_total": 36, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-42-01", "timestamp": 1606318921, "training_iteration": 20, "time_this_iter_s": 7.0638508796691895, "time_total_s": 192.4771327972412, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def62860>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def62a20>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 192.4771327972412, "timesteps_since_restore": 39000, "iterations_since_restore": 20}
{"episode_reward_max": 574.0, "episode_reward_min": -1254.0, "episode_reward_mean": 193.8421052631579, "episode_len_mean": 1000.0, "episodes_this_iter": 2, "policy_reward_mean": {"agent-0": 52.526315789473685, "agent-1": 31.710526315789473, "agent-2": 28.473684210526315, "agent-3": 36.94736842105263, "agent-4": 44.18421052631579}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 41000, "num_steps_sampled": 41000, "wait_time_ms": 6.43, "apply_time_ms": 8.423, "dispatch_time_ms": 24.028, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 41000, "episodes_total": 38, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-42-08", "timestamp": 1606318928, "training_iteration": 21, "time_this_iter_s": 7.149144887924194, "time_total_s": 199.6262776851654, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def735c0>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def8d198>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 199.6262776851654, "timesteps_since_restore": 41000, "iterations_since_restore": 21}
{"episode_reward_max": 589.0, "episode_reward_min": -1254.0, "episode_reward_mean": 228.0, "episode_len_mean": 1000.0, "episodes_this_iter": 4, "policy_reward_mean": {"agent-0": 56.642857142857146, "agent-1": 39.142857142857146, "agent-2": 36.54761904761905, "agent-3": 44.023809523809526, "agent-4": 51.642857142857146}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 43000, "num_steps_sampled": 43000, "wait_time_ms": 5.23, "apply_time_ms": 7.415, "dispatch_time_ms": 26.373, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 43000, "episodes_total": 42, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-42-15", "timestamp": 1606318935, "training_iteration": 22, "time_this_iter_s": 6.884439468383789, "time_total_s": 206.5107171535492, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def8d400>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def8d2e8>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 206.5107171535492, "timesteps_since_restore": 43000, "iterations_since_restore": 22}
{"episode_reward_max": 589.0, "episode_reward_min": -1254.0, "episode_reward_mean": 228.0, "episode_len_mean": 1000.0, "episodes_this_iter": 0, "policy_reward_mean": {"agent-0": 56.642857142857146, "agent-1": 39.142857142857146, "agent-2": 36.54761904761905, "agent-3": 44.023809523809526, "agent-4": 51.642857142857146}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 45000, "num_steps_sampled": 45000, "wait_time_ms": 7.637, "apply_time_ms": 7.187, "dispatch_time_ms": 26.939, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 45000, "episodes_total": 42, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-42-22", "timestamp": 1606318942, "training_iteration": 23, "time_this_iter_s": 7.1319286823272705, "time_total_s": 213.64264583587646, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def73b70>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def8de10>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 213.64264583587646, "timesteps_since_restore": 45000, "iterations_since_restore": 23}
{"episode_reward_max": 589.0, "episode_reward_min": -1254.0, "episode_reward_mean": 239.88636363636363, "episode_len_mean": 1000.0, "episodes_this_iter": 2, "policy_reward_mean": {"agent-0": 58.59090909090909, "agent-1": 41.52272727272727, "agent-2": 40.18181818181818, "agent-3": 45.81818181818182, "agent-4": 53.77272727272727}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 47000, "num_steps_sampled": 47000, "wait_time_ms": 9.793, "apply_time_ms": 7.604, "dispatch_time_ms": 24.756, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 47000, "episodes_total": 44, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-42-29", "timestamp": 1606318949, "training_iteration": 24, "time_this_iter_s": 7.043521165847778, "time_total_s": 220.68616700172424, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def8d278>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def8d748>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 220.68616700172424, "timesteps_since_restore": 47000, "iterations_since_restore": 24}
{"episode_reward_max": 589.0, "episode_reward_min": -1254.0, "episode_reward_mean": 256.36170212765956, "episode_len_mean": 1000.0, "episodes_this_iter": 3, "policy_reward_mean": {"agent-0": 60.0, "agent-1": 44.93617021276596, "agent-2": 44.702127659574465, "agent-3": 49.638297872340424, "agent-4": 57.08510638297872}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 49000, "num_steps_sampled": 49000, "wait_time_ms": 8.937, "apply_time_ms": 8.101, "dispatch_time_ms": 24.545, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 49000, "episodes_total": 47, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-42-36", "timestamp": 1606318956, "training_iteration": 25, "time_this_iter_s": 7.063650846481323, "time_total_s": 227.74981784820557, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def73cf8>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def8dcc0>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 227.74981784820557, "timesteps_since_restore": 49000, "iterations_since_restore": 25}
{"episode_reward_max": 589.0, "episode_reward_min": -1254.0, "episode_reward_mean": 262.8541666666667, "episode_len_mean": 1000.0, "episodes_this_iter": 1, "policy_reward_mean": {"agent-0": 60.625, "agent-1": 46.395833333333336, "agent-2": 46.375, "agent-3": 50.9375, "agent-4": 58.520833333333336}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 51000, "num_steps_sampled": 51000, "wait_time_ms": 6.905, "apply_time_ms": 7.516, "dispatch_time_ms": 26.804, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 51000, "episodes_total": 48, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-42-43", "timestamp": 1606318963, "training_iteration": 26, "time_this_iter_s": 7.084798812866211, "time_total_s": 234.83461666107178, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def8d3c8>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def8dc88>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 234.83461666107178, "timesteps_since_restore": 51000, "iterations_since_restore": 26}
{"episode_reward_max": 589.0, "episode_reward_min": -1254.0, "episode_reward_mean": 276.27450980392155, "episode_len_mean": 1000.0, "episodes_this_iter": 3, "policy_reward_mean": {"agent-0": 63.15686274509804, "agent-1": 49.80392156862745, "agent-2": 48.94117647058823, "agent-3": 52.490196078431374, "agent-4": 61.88235294117647}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 53000, "num_steps_sampled": 53000, "wait_time_ms": 7.242, "apply_time_ms": 7.838, "dispatch_time_ms": 25.604, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 53000, "episodes_total": 51, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-42-51", "timestamp": 1606318971, "training_iteration": 27, "time_this_iter_s": 7.093713045120239, "time_total_s": 241.92832970619202, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def735c0>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def73b70>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 241.92832970619202, "timesteps_since_restore": 53000, "iterations_since_restore": 27}
{"episode_reward_max": 589.0, "episode_reward_min": -1254.0, "episode_reward_mean": 286.49056603773585, "episode_len_mean": 1000.0, "episodes_this_iter": 2, "policy_reward_mean": {"agent-0": 65.18867924528301, "agent-1": 51.528301886792455, "agent-2": 51.490566037735846, "agent-3": 54.79245283018868, "agent-4": 63.490566037735846}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 55000, "num_steps_sampled": 55000, "wait_time_ms": 10.579, "apply_time_ms": 8.382, "dispatch_time_ms": 22.248, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 55000, "episodes_total": 53, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-42-58", "timestamp": 1606318978, "training_iteration": 28, "time_this_iter_s": 7.086968660354614, "time_total_s": 249.01529836654663, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def8d5f8>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def8d780>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 249.01529836654663, "timesteps_since_restore": 55000, "iterations_since_restore": 28}
{"episode_reward_max": 589.0, "episode_reward_min": -1254.0, "episode_reward_mean": 289.5925925925926, "episode_len_mean": 1000.0, "episodes_this_iter": 1, "policy_reward_mean": {"agent-0": 66.0, "agent-1": 52.870370370370374, "agent-2": 52.5, "agent-3": 54.425925925925924, "agent-4": 63.7962962962963}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 57000, "num_steps_sampled": 57000, "wait_time_ms": 8.292, "apply_time_ms": 7.246, "dispatch_time_ms": 23.27, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 57000, "episodes_total": 54, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-43-05", "timestamp": 1606318985, "training_iteration": 29, "time_this_iter_s": 7.096899747848511, "time_total_s": 256.11219811439514, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def8de10>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def8d9e8>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 256.11219811439514, "timesteps_since_restore": 57000, "iterations_since_restore": 29}
{"episode_reward_max": 626.0, "episode_reward_min": -1254.0, "episode_reward_mean": 302.9298245614035, "episode_len_mean": 1000.0, "episodes_this_iter": 3, "policy_reward_mean": {"agent-0": 66.56140350877193, "agent-1": 55.228070175438596, "agent-2": 55.63157894736842, "agent-3": 58.75438596491228, "agent-4": 66.75438596491227}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 59000, "num_steps_sampled": 59000, "wait_time_ms": 6.151, "apply_time_ms": 7.897, "dispatch_time_ms": 24.75, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 59000, "episodes_total": 57, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-43-12", "timestamp": 1606318992, "training_iteration": 30, "time_this_iter_s": 6.98486328125, "time_total_s": 263.09706139564514, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def8d588>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def75710>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 263.09706139564514, "timesteps_since_restore": 59000, "iterations_since_restore": 30}
{"episode_reward_max": 626.0, "episode_reward_min": -1254.0, "episode_reward_mean": 309.9830508474576, "episode_len_mean": 1000.0, "episodes_this_iter": 2, "policy_reward_mean": {"agent-0": 66.83050847457628, "agent-1": 56.728813559322035, "agent-2": 57.983050847457626, "agent-3": 59.69491525423729, "agent-4": 68.7457627118644}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 61000, "num_steps_sampled": 61000, "wait_time_ms": 5.883, "apply_time_ms": 8.141, "dispatch_time_ms": 23.383, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 61000, "episodes_total": 59, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-43-19", "timestamp": 1606318999, "training_iteration": 31, "time_this_iter_s": 7.10217547416687, "time_total_s": 270.199236869812, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def8d630>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def75f60>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 270.199236869812, "timesteps_since_restore": 61000, "iterations_since_restore": 31}
{"episode_reward_max": 626.0, "episode_reward_min": -1254.0, "episode_reward_mean": 313.0, "episode_len_mean": 1000.0, "episodes_this_iter": 1, "policy_reward_mean": {"agent-0": 66.61666666666666, "agent-1": 57.8, "agent-2": 58.733333333333334, "agent-3": 60.333333333333336, "agent-4": 69.51666666666667}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 63000, "num_steps_sampled": 63000, "wait_time_ms": 11.224, "apply_time_ms": 7.637, "dispatch_time_ms": 25.521, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 63000, "episodes_total": 60, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-43-26", "timestamp": 1606319006, "training_iteration": 32, "time_this_iter_s": 7.062344789505005, "time_total_s": 277.261581659317, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def62f28>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def75470>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 277.261581659317, "timesteps_since_restore": 63000, "iterations_since_restore": 32}
{"episode_reward_max": 626.0, "episode_reward_min": -1254.0, "episode_reward_mean": 320.95238095238096, "episode_len_mean": 1000.0, "episodes_this_iter": 3, "policy_reward_mean": {"agent-0": 67.98412698412699, "agent-1": 59.476190476190474, "agent-2": 61.285714285714285, "agent-3": 62.03174603174603, "agent-4": 70.17460317460318}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 65000, "num_steps_sampled": 65000, "wait_time_ms": 6.586, "apply_time_ms": 7.943, "dispatch_time_ms": 23.693, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 65000, "episodes_total": 63, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-43-33", "timestamp": 1606319013, "training_iteration": 33, "time_this_iter_s": 6.99194598197937, "time_total_s": 284.2535276412964, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def8d6a0>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def75b38>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 284.2535276412964, "timesteps_since_restore": 65000, "iterations_since_restore": 33}
{"episode_reward_max": 626.0, "episode_reward_min": -1254.0, "episode_reward_mean": 325.0153846153846, "episode_len_mean": 1000.0, "episodes_this_iter": 2, "policy_reward_mean": {"agent-0": 68.95384615384616, "agent-1": 61.8, "agent-2": 60.738461538461536, "agent-3": 62.89230769230769, "agent-4": 70.63076923076923}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 67000, "num_steps_sampled": 67000, "wait_time_ms": 6.942, "apply_time_ms": 7.41, "dispatch_time_ms": 24.677, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 67000, "episodes_total": 65, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-43-40", "timestamp": 1606319020, "training_iteration": 34, "time_this_iter_s": 7.083196401596069, "time_total_s": 291.33672404289246, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def8d5f8>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def732b0>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 291.33672404289246, "timesteps_since_restore": 67000, "iterations_since_restore": 34}
{"episode_reward_max": 626.0, "episode_reward_min": -1254.0, "episode_reward_mean": 328.7121212121212, "episode_len_mean": 1000.0, "episodes_this_iter": 1, "policy_reward_mean": {"agent-0": 68.98484848484848, "agent-1": 62.803030303030305, "agent-2": 61.74242424242424, "agent-3": 63.96969696969697, "agent-4": 71.21212121212122}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 69000, "num_steps_sampled": 69000, "wait_time_ms": 10.535, "apply_time_ms": 7.796, "dispatch_time_ms": 22.482, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 69000, "episodes_total": 66, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-43-47", "timestamp": 1606319027, "training_iteration": 35, "time_this_iter_s": 7.1104209423065186, "time_total_s": 298.447144985199, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def62f28>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def750b8>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 298.447144985199, "timesteps_since_restore": 69000, "iterations_since_restore": 35}
{"episode_reward_max": 626.0, "episode_reward_min": -1254.0, "episode_reward_mean": 336.42028985507244, "episode_len_mean": 1000.0, "episodes_this_iter": 3, "policy_reward_mean": {"agent-0": 70.4927536231884, "agent-1": 63.710144927536234, "agent-2": 63.710144927536234, "agent-3": 65.8840579710145, "agent-4": 72.6231884057971}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 71000, "num_steps_sampled": 71000, "wait_time_ms": 9.898, "apply_time_ms": 8.759, "dispatch_time_ms": 24.646, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 71000, "episodes_total": 69, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-43-55", "timestamp": 1606319035, "training_iteration": 36, "time_this_iter_s": 7.312082052230835, "time_total_s": 305.7592270374298, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def8d7b8>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def8d208>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 305.7592270374298, "timesteps_since_restore": 71000, "iterations_since_restore": 36}
{"episode_reward_max": 626.0, "episode_reward_min": -1254.0, "episode_reward_mean": 339.1, "episode_len_mean": 1000.0, "episodes_this_iter": 1, "policy_reward_mean": {"agent-0": 70.71428571428571, "agent-1": 63.8, "agent-2": 64.91428571428571, "agent-3": 66.35714285714286, "agent-4": 73.31428571428572}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 73000, "num_steps_sampled": 73000, "wait_time_ms": 7.508, "apply_time_ms": 7.598, "dispatch_time_ms": 26.195, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 73000, "episodes_total": 70, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-44-02", "timestamp": 1606319042, "training_iteration": 37, "time_this_iter_s": 7.39221715927124, "time_total_s": 313.15144419670105, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def730b8>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def75978>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 313.15144419670105, "timesteps_since_restore": 73000, "iterations_since_restore": 37}
{"episode_reward_max": 626.0, "episode_reward_min": -1254.0, "episode_reward_mean": 343.0833333333333, "episode_len_mean": 1000.0, "episodes_this_iter": 2, "policy_reward_mean": {"agent-0": 71.06944444444444, "agent-1": 64.72222222222223, "agent-2": 65.51388888888889, "agent-3": 66.77777777777777, "agent-4": 75.0}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 75000, "num_steps_sampled": 75000, "wait_time_ms": 8.081, "apply_time_ms": 7.994, "dispatch_time_ms": 24.281, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 75000, "episodes_total": 72, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-44-09", "timestamp": 1606319049, "training_iteration": 38, "time_this_iter_s": 7.03689980506897, "time_total_s": 320.18834400177, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def8d2b0>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def75278>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 320.18834400177, "timesteps_since_restore": 75000, "iterations_since_restore": 38}
{"episode_reward_max": 626.0, "episode_reward_min": -1254.0, "episode_reward_mean": 349.73333333333335, "episode_len_mean": 1000.0, "episodes_this_iter": 3, "policy_reward_mean": {"agent-0": 72.70666666666666, "agent-1": 66.24, "agent-2": 67.38666666666667, "agent-3": 68.0, "agent-4": 75.4}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 77000, "num_steps_sampled": 77000, "wait_time_ms": 8.703, "apply_time_ms": 8.084, "dispatch_time_ms": 25.329, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 77000, "episodes_total": 75, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-44-16", "timestamp": 1606319056, "training_iteration": 39, "time_this_iter_s": 7.105043649673462, "time_total_s": 327.2933876514435, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def73cc0>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def75128>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 327.2933876514435, "timesteps_since_restore": 77000, "iterations_since_restore": 39}
{"episode_reward_max": 626.0, "episode_reward_min": -1254.0, "episode_reward_mean": 351.82894736842104, "episode_len_mean": 1000.0, "episodes_this_iter": 1, "policy_reward_mean": {"agent-0": 72.84210526315789, "agent-1": 66.72368421052632, "agent-2": 67.89473684210526, "agent-3": 68.13157894736842, "agent-4": 76.23684210526316}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 79000, "num_steps_sampled": 79000, "wait_time_ms": 10.673, "apply_time_ms": 7.703, "dispatch_time_ms": 26.126, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 79000, "episodes_total": 76, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-44-23", "timestamp": 1606319063, "training_iteration": 40, "time_this_iter_s": 6.991595506668091, "time_total_s": 334.2849831581116, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def8d9b0>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def75588>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 334.2849831581116, "timesteps_since_restore": 79000, "iterations_since_restore": 40}
{"episode_reward_max": 626.0, "episode_reward_min": -1254.0, "episode_reward_mean": 355.6923076923077, "episode_len_mean": 1000.0, "episodes_this_iter": 2, "policy_reward_mean": {"agent-0": 73.62820512820512, "agent-1": 67.51282051282051, "agent-2": 68.43589743589743, "agent-3": 68.97435897435898, "agent-4": 77.14102564102564}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 81000, "num_steps_sampled": 81000, "wait_time_ms": 6.758, "apply_time_ms": 7.81, "dispatch_time_ms": 23.068, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 81000, "episodes_total": 78, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-44-30", "timestamp": 1606319070, "training_iteration": 41, "time_this_iter_s": 7.0297911167144775, "time_total_s": 341.31477427482605, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def62b00>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def8d6a0>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 341.31477427482605, "timesteps_since_restore": 81000, "iterations_since_restore": 41}
{"episode_reward_max": 626.0, "episode_reward_min": -1254.0, "episode_reward_mean": 361.48148148148147, "episode_len_mean": 1000.0, "episodes_this_iter": 3, "policy_reward_mean": {"agent-0": 75.32098765432099, "agent-1": 68.96296296296296, "agent-2": 69.14814814814815, "agent-3": 69.5925925925926, "agent-4": 78.45679012345678}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 83000, "num_steps_sampled": 83000, "wait_time_ms": 11.616, "apply_time_ms": 7.696, "dispatch_time_ms": 24.711, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 83000, "episodes_total": 81, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-44-37", "timestamp": 1606319077, "training_iteration": 42, "time_this_iter_s": 7.171142101287842, "time_total_s": 348.4859163761139, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def75be0>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def75ac8>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 348.4859163761139, "timesteps_since_restore": 83000, "iterations_since_restore": 42}
{"episode_reward_max": 626.0, "episode_reward_min": -1254.0, "episode_reward_mean": 363.1707317073171, "episode_len_mean": 1000.0, "episodes_this_iter": 1, "policy_reward_mean": {"agent-0": 75.29268292682927, "agent-1": 69.14634146341463, "agent-2": 70.1951219512195, "agent-3": 69.5, "agent-4": 79.03658536585365}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 85000, "num_steps_sampled": 85000, "wait_time_ms": 5.877, "apply_time_ms": 7.176, "dispatch_time_ms": 25.638, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 85000, "episodes_total": 82, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-44-44", "timestamp": 1606319084, "training_iteration": 43, "time_this_iter_s": 6.943752288818359, "time_total_s": 355.42966866493225, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def62128>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def8d128>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 355.42966866493225, "timesteps_since_restore": 85000, "iterations_since_restore": 43}
{"episode_reward_max": 626.0, "episode_reward_min": -1254.0, "episode_reward_mean": 366.6547619047619, "episode_len_mean": 1000.0, "episodes_this_iter": 2, "policy_reward_mean": {"agent-0": 76.05952380952381, "agent-1": 70.02380952380952, "agent-2": 70.28571428571429, "agent-3": 70.29761904761905, "agent-4": 79.98809523809524}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 87000, "num_steps_sampled": 87000, "wait_time_ms": 8.216, "apply_time_ms": 8.232, "dispatch_time_ms": 24.977, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 87000, "episodes_total": 84, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-44-51", "timestamp": 1606319091, "training_iteration": 44, "time_this_iter_s": 7.018342018127441, "time_total_s": 362.4480106830597, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def75a20>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def75160>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 362.4480106830597, "timesteps_since_restore": 87000, "iterations_since_restore": 44}
{"episode_reward_max": 626.0, "episode_reward_min": -1254.0, "episode_reward_mean": 370.67816091954023, "episode_len_mean": 1000.0, "episodes_this_iter": 3, "policy_reward_mean": {"agent-0": 77.06896551724138, "agent-1": 71.86206896551724, "agent-2": 70.98850574712644, "agent-3": 70.39080459770115, "agent-4": 80.36781609195403}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 89000, "num_steps_sampled": 89000, "wait_time_ms": 6.406, "apply_time_ms": 8.115, "dispatch_time_ms": 23.62, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 89000, "episodes_total": 87, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-44-59", "timestamp": 1606319099, "training_iteration": 45, "time_this_iter_s": 7.0303709506988525, "time_total_s": 369.47838163375854, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def62f28>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def757f0>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 369.47838163375854, "timesteps_since_restore": 89000, "iterations_since_restore": 45}
{"episode_reward_max": 626.0, "episode_reward_min": -1254.0, "episode_reward_mean": 371.95454545454544, "episode_len_mean": 1000.0, "episodes_this_iter": 1, "policy_reward_mean": {"agent-0": 77.32954545454545, "agent-1": 72.54545454545455, "agent-2": 70.7840909090909, "agent-3": 70.93181818181819, "agent-4": 80.36363636363636}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 91000, "num_steps_sampled": 91000, "wait_time_ms": 6.754, "apply_time_ms": 8.461, "dispatch_time_ms": 25.557, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 91000, "episodes_total": 88, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-45-06", "timestamp": 1606319106, "training_iteration": 46, "time_this_iter_s": 7.08517599105835, "time_total_s": 376.5635576248169, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def759e8>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def75cf8>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 376.5635576248169, "timesteps_since_restore": 91000, "iterations_since_restore": 46}
{"episode_reward_max": 626.0, "episode_reward_min": -1254.0, "episode_reward_mean": 375.3888888888889, "episode_len_mean": 1000.0, "episodes_this_iter": 2, "policy_reward_mean": {"agent-0": 77.97777777777777, "agent-1": 72.81111111111112, "agent-2": 71.36666666666666, "agent-3": 72.1, "agent-4": 81.13333333333334}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 93000, "num_steps_sampled": 93000, "wait_time_ms": 6.202, "apply_time_ms": 7.659, "dispatch_time_ms": 24.228, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 93000, "episodes_total": 90, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-45-13", "timestamp": 1606319113, "training_iteration": 47, "time_this_iter_s": 7.3386218547821045, "time_total_s": 383.902179479599, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def626d8>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def73cc0>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 383.902179479599, "timesteps_since_restore": 93000, "iterations_since_restore": 47}
{"episode_reward_max": 626.0, "episode_reward_min": -1254.0, "episode_reward_mean": 379.73118279569894, "episode_len_mean": 1000.0, "episodes_this_iter": 3, "policy_reward_mean": {"agent-0": 79.23655913978494, "agent-1": 73.18279569892474, "agent-2": 72.44086021505376, "agent-3": 72.94623655913979, "agent-4": 81.9247311827957}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 95000, "num_steps_sampled": 95000, "wait_time_ms": 8.771, "apply_time_ms": 7.722, "dispatch_time_ms": 23.896, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 95000, "episodes_total": 93, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-45-20", "timestamp": 1606319120, "training_iteration": 48, "time_this_iter_s": 7.019093990325928, "time_total_s": 390.9212734699249, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def75940>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def62668>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 390.9212734699249, "timesteps_since_restore": 95000, "iterations_since_restore": 48}
{"episode_reward_max": 626.0, "episode_reward_min": -1254.0, "episode_reward_mean": 380.75531914893617, "episode_len_mean": 1000.0, "episodes_this_iter": 1, "policy_reward_mean": {"agent-0": 79.69148936170212, "agent-1": 73.31914893617021, "agent-2": 72.72340425531915, "agent-3": 72.85106382978724, "agent-4": 82.17021276595744}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 97000, "num_steps_sampled": 97000, "wait_time_ms": 7.172, "apply_time_ms": 8.685, "dispatch_time_ms": 27.286, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 97000, "episodes_total": 94, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-45-27", "timestamp": 1606319127, "training_iteration": 49, "time_this_iter_s": 7.1043195724487305, "time_total_s": 398.02559304237366, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def62b00>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def73780>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 398.02559304237366, "timesteps_since_restore": 97000, "iterations_since_restore": 49}
{"episode_reward_max": 626.0, "episode_reward_min": -1254.0, "episode_reward_mean": 383.59375, "episode_len_mean": 1000.0, "episodes_this_iter": 2, "policy_reward_mean": {"agent-0": 80.28125, "agent-1": 73.5625, "agent-2": 74.20833333333333, "agent-3": 73.0, "agent-4": 82.54166666666667}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 99000, "num_steps_sampled": 99000, "wait_time_ms": 7.06, "apply_time_ms": 7.691, "dispatch_time_ms": 25.68, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 99000, "episodes_total": 96, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-45-34", "timestamp": 1606319134, "training_iteration": 50, "time_this_iter_s": 7.149889945983887, "time_total_s": 405.17548298835754, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def75748>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def754a8>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 405.17548298835754, "timesteps_since_restore": 99000, "iterations_since_restore": 50}
{"episode_reward_max": 626.0, "episode_reward_min": -1254.0, "episode_reward_mean": 387.8484848484849, "episode_len_mean": 1000.0, "episodes_this_iter": 3, "policy_reward_mean": {"agent-0": 80.76767676767676, "agent-1": 74.68686868686869, "agent-2": 75.0909090909091, "agent-3": 73.95959595959596, "agent-4": 83.34343434343434}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 101000, "num_steps_sampled": 101000, "wait_time_ms": 7.599, "apply_time_ms": 7.743, "dispatch_time_ms": 24.683, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 101000, "episodes_total": 99, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-45-41", "timestamp": 1606319141, "training_iteration": 51, "time_this_iter_s": 7.072674036026001, "time_total_s": 412.24815702438354, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def757b8>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def625f8>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 412.24815702438354, "timesteps_since_restore": 101000, "iterations_since_restore": 51}
{"episode_reward_max": 626.0, "episode_reward_min": -1254.0, "episode_reward_mean": 389.27, "episode_len_mean": 1000.0, "episodes_this_iter": 1, "policy_reward_mean": {"agent-0": 80.54, "agent-1": 74.84, "agent-2": 75.56, "agent-3": 74.45, "agent-4": 83.88}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 103000, "num_steps_sampled": 103000, "wait_time_ms": 6.541, "apply_time_ms": 8.645, "dispatch_time_ms": 24.393, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 103000, "episodes_total": 100, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-45-48", "timestamp": 1606319148, "training_iteration": 52, "time_this_iter_s": 7.030829191207886, "time_total_s": 419.27898621559143, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def756d8>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def75e10>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 419.27898621559143, "timesteps_since_restore": 103000, "iterations_since_restore": 52}
{"episode_reward_max": 626.0, "episode_reward_min": -1254.0, "episode_reward_mean": 412.25, "episode_len_mean": 1000.0, "episodes_this_iter": 2, "policy_reward_mean": {"agent-0": 86.24, "agent-1": 77.69, "agent-2": 81.98, "agent-3": 78.31, "agent-4": 88.03}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 105000, "num_steps_sampled": 105000, "wait_time_ms": 8.743, "apply_time_ms": 8.301, "dispatch_time_ms": 24.763, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 105000, "episodes_total": 102, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-45-56", "timestamp": 1606319156, "training_iteration": 53, "time_this_iter_s": 7.205090045928955, "time_total_s": 426.4840762615204, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def73a90>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def62518>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 426.4840762615204, "timesteps_since_restore": 105000, "iterations_since_restore": 53}
{"episode_reward_max": 626.0, "episode_reward_min": -961.0, "episode_reward_mean": 457.49, "episode_len_mean": 1000.0, "episodes_this_iter": 3, "policy_reward_mean": {"agent-0": 95.79, "agent-1": 87.51, "agent-2": 89.18, "agent-3": 85.02, "agent-4": 99.99}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 107000, "num_steps_sampled": 107000, "wait_time_ms": 6.426, "apply_time_ms": 7.471, "dispatch_time_ms": 24.881, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 107000, "episodes_total": 105, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-46-03", "timestamp": 1606319163, "training_iteration": 54, "time_this_iter_s": 7.070524215698242, "time_total_s": 433.5546004772186, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def75da0>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def75e48>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 433.5546004772186, "timesteps_since_restore": 107000, "iterations_since_restore": 54}
{"episode_reward_max": 626.0, "episode_reward_min": -240.0, "episode_reward_mean": 472.44, "episode_len_mean": 1000.0, "episodes_this_iter": 1, "policy_reward_mean": {"agent-0": 96.58, "agent-1": 91.93, "agent-2": 92.12, "agent-3": 90.57, "agent-4": 101.24}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 109000, "num_steps_sampled": 109000, "wait_time_ms": 6.819, "apply_time_ms": 7.73, "dispatch_time_ms": 23.686, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 109000, "episodes_total": 106, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-46-10", "timestamp": 1606319170, "training_iteration": 55, "time_this_iter_s": 7.119722127914429, "time_total_s": 440.67432260513306, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def73780>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def73ba8>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 440.67432260513306, "timesteps_since_restore": 109000, "iterations_since_restore": 55}
{"episode_reward_max": 626.0, "episode_reward_min": -240.0, "episode_reward_mean": 474.77, "episode_len_mean": 1000.0, "episodes_this_iter": 1, "policy_reward_mean": {"agent-0": 96.54, "agent-1": 92.54, "agent-2": 92.27, "agent-3": 91.06, "agent-4": 102.36}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 111000, "num_steps_sampled": 111000, "wait_time_ms": 7.912, "apply_time_ms": 8.244, "dispatch_time_ms": 25.723, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 111000, "episodes_total": 107, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-46-17", "timestamp": 1606319177, "training_iteration": 56, "time_this_iter_s": 7.067321300506592, "time_total_s": 447.74164390563965, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def75518>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def756d8>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 447.74164390563965, "timesteps_since_restore": 111000, "iterations_since_restore": 56}
{"episode_reward_max": 626.0, "episode_reward_min": -33.0, "episode_reward_mean": 492.33, "episode_len_mean": 1000.0, "episodes_this_iter": 4, "policy_reward_mean": {"agent-0": 98.64, "agent-1": 94.65, "agent-2": 97.23, "agent-3": 94.85, "agent-4": 106.96}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 113000, "num_steps_sampled": 113000, "wait_time_ms": 7.804, "apply_time_ms": 8.514, "dispatch_time_ms": 24.936, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 113000, "episodes_total": 111, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-46-24", "timestamp": 1606319184, "training_iteration": 57, "time_this_iter_s": 7.048387289047241, "time_total_s": 454.7900311946869, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def62470>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def62cc0>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 454.7900311946869, "timesteps_since_restore": 113000, "iterations_since_restore": 57}
{"episode_reward_max": 626.0, "episode_reward_min": 281.0, "episode_reward_mean": 497.25, "episode_len_mean": 1000.0, "episodes_this_iter": 1, "policy_reward_mean": {"agent-0": 99.29, "agent-1": 96.66, "agent-2": 98.55, "agent-3": 94.53, "agent-4": 108.22}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 115000, "num_steps_sampled": 115000, "wait_time_ms": 7.877, "apply_time_ms": 7.166, "dispatch_time_ms": 24.914, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 115000, "episodes_total": 112, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-46-31", "timestamp": 1606319191, "training_iteration": 58, "time_this_iter_s": 7.020776033401489, "time_total_s": 461.8108072280884, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def75ac8>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def62b70>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 461.8108072280884, "timesteps_since_restore": 115000, "iterations_since_restore": 58}
{"episode_reward_max": 626.0, "episode_reward_min": 308.0, "episode_reward_mean": 499.16, "episode_len_mean": 1000.0, "episodes_this_iter": 1, "policy_reward_mean": {"agent-0": 99.54, "agent-1": 96.97, "agent-2": 99.38, "agent-3": 94.94, "agent-4": 108.33}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 117000, "num_steps_sampled": 117000, "wait_time_ms": 6.983, "apply_time_ms": 8.366, "dispatch_time_ms": 24.278, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 117000, "episodes_total": 113, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-46-38", "timestamp": 1606319198, "training_iteration": 59, "time_this_iter_s": 7.094897031784058, "time_total_s": 468.90570425987244, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def62f28>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def62e10>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 468.90570425987244, "timesteps_since_restore": 117000, "iterations_since_restore": 59}
{"episode_reward_max": 626.0, "episode_reward_min": 319.0, "episode_reward_mean": 503.97, "episode_len_mean": 1000.0, "episodes_this_iter": 4, "policy_reward_mean": {"agent-0": 97.78, "agent-1": 98.1, "agent-2": 102.43, "agent-3": 96.29, "agent-4": 109.37}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 119000, "num_steps_sampled": 119000, "wait_time_ms": 6.931, "apply_time_ms": 8.23, "dispatch_time_ms": 24.429, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 119000, "episodes_total": 117, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-46-45", "timestamp": 1606319205, "training_iteration": 60, "time_this_iter_s": 7.09907865524292, "time_total_s": 476.00478291511536, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def75518>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def75cc0>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 476.00478291511536, "timesteps_since_restore": 119000, "iterations_since_restore": 60}
{"episode_reward_max": 626.0, "episode_reward_min": 319.0, "episode_reward_mean": 505.21, "episode_len_mean": 1000.0, "episodes_this_iter": 1, "policy_reward_mean": {"agent-0": 97.81, "agent-1": 98.22, "agent-2": 103.06, "agent-3": 96.54, "agent-4": 109.58}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 121000, "num_steps_sampled": 121000, "wait_time_ms": 7.871, "apply_time_ms": 7.358, "dispatch_time_ms": 23.816, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 121000, "episodes_total": 118, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-46-52", "timestamp": 1606319212, "training_iteration": 61, "time_this_iter_s": 7.085901975631714, "time_total_s": 483.09068489074707, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa340eb4160>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def62e80>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 483.09068489074707, "timesteps_since_restore": 121000, "iterations_since_restore": 61}
{"episode_reward_max": 626.0, "episode_reward_min": 319.0, "episode_reward_mean": 506.09, "episode_len_mean": 1000.0, "episodes_this_iter": 1, "policy_reward_mean": {"agent-0": 97.79, "agent-1": 98.49, "agent-2": 103.92, "agent-3": 96.43, "agent-4": 109.46}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 123000, "num_steps_sampled": 123000, "wait_time_ms": 8.81, "apply_time_ms": 8.081, "dispatch_time_ms": 25.2, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 123000, "episodes_total": 119, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-47-00", "timestamp": 1606319220, "training_iteration": 62, "time_this_iter_s": 7.192832708358765, "time_total_s": 490.28351759910583, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def87198>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def87b00>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 490.28351759910583, "timesteps_since_restore": 123000, "iterations_since_restore": 62}
{"episode_reward_max": 626.0, "episode_reward_min": 372.0, "episode_reward_mean": 510.1, "episode_len_mean": 1000.0, "episodes_this_iter": 4, "policy_reward_mean": {"agent-0": 97.4, "agent-1": 99.98, "agent-2": 104.44, "agent-3": 98.42, "agent-4": 109.86}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 125000, "num_steps_sampled": 125000, "wait_time_ms": 9.719, "apply_time_ms": 7.787, "dispatch_time_ms": 25.882, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 125000, "episodes_total": 123, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-47-07", "timestamp": 1606319227, "training_iteration": 63, "time_this_iter_s": 7.114505052566528, "time_total_s": 497.39802265167236, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def8d160>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def62668>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 497.39802265167236, "timesteps_since_restore": 125000, "iterations_since_restore": 63}
{"episode_reward_max": 626.0, "episode_reward_min": 372.0, "episode_reward_mean": 511.38, "episode_len_mean": 1000.0, "episodes_this_iter": 1, "policy_reward_mean": {"agent-0": 97.7, "agent-1": 100.36, "agent-2": 104.59, "agent-3": 98.96, "agent-4": 109.77}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 127000, "num_steps_sampled": 127000, "wait_time_ms": 9.131, "apply_time_ms": 8.212, "dispatch_time_ms": 23.55, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 127000, "episodes_total": 124, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-47-14", "timestamp": 1606319234, "training_iteration": 64, "time_this_iter_s": 7.103357315063477, "time_total_s": 504.50137996673584, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def753c8>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def87d30>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 504.50137996673584, "timesteps_since_restore": 127000, "iterations_since_restore": 64}
{"episode_reward_max": 626.0, "episode_reward_min": 372.0, "episode_reward_mean": 510.48, "episode_len_mean": 1000.0, "episodes_this_iter": 1, "policy_reward_mean": {"agent-0": 97.28, "agent-1": 100.23, "agent-2": 104.24, "agent-3": 99.03, "agent-4": 109.7}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 129000, "num_steps_sampled": 129000, "wait_time_ms": 7.607, "apply_time_ms": 8.491, "dispatch_time_ms": 24.624, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 129000, "episodes_total": 125, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-47-21", "timestamp": 1606319241, "training_iteration": 65, "time_this_iter_s": 7.098558187484741, "time_total_s": 511.5999381542206, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def8d2e8>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def624a8>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 511.5999381542206, "timesteps_since_restore": 129000, "iterations_since_restore": 65}
{"episode_reward_max": 626.0, "episode_reward_min": 372.0, "episode_reward_mean": 511.93, "episode_len_mean": 1000.0, "episodes_this_iter": 4, "policy_reward_mean": {"agent-0": 97.41, "agent-1": 100.35, "agent-2": 104.93, "agent-3": 99.87, "agent-4": 109.37}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 131000, "num_steps_sampled": 131000, "wait_time_ms": 8.75, "apply_time_ms": 8.011, "dispatch_time_ms": 24.783, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 131000, "episodes_total": 129, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-47-28", "timestamp": 1606319248, "training_iteration": 66, "time_this_iter_s": 7.136768102645874, "time_total_s": 518.7367062568665, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def756a0>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def87b70>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 518.7367062568665, "timesteps_since_restore": 131000, "iterations_since_restore": 66}
{"episode_reward_max": 626.0, "episode_reward_min": 372.0, "episode_reward_mean": 513.47, "episode_len_mean": 1000.0, "episodes_this_iter": 1, "policy_reward_mean": {"agent-0": 97.68, "agent-1": 100.7, "agent-2": 105.29, "agent-3": 100.51, "agent-4": 109.29}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 133000, "num_steps_sampled": 133000, "wait_time_ms": 7.558, "apply_time_ms": 7.956, "dispatch_time_ms": 23.263, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 133000, "episodes_total": 130, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-47-35", "timestamp": 1606319255, "training_iteration": 67, "time_this_iter_s": 7.036715745925903, "time_total_s": 525.7734220027924, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def8de48>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def62390>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 525.7734220027924, "timesteps_since_restore": 133000, "iterations_since_restore": 67}
{"episode_reward_max": 626.0, "episode_reward_min": 372.0, "episode_reward_mean": 514.32, "episode_len_mean": 1000.0, "episodes_this_iter": 1, "policy_reward_mean": {"agent-0": 97.75, "agent-1": 100.68, "agent-2": 105.36, "agent-3": 100.74, "agent-4": 109.79}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 135000, "num_steps_sampled": 135000, "wait_time_ms": 7.978, "apply_time_ms": 7.878, "dispatch_time_ms": 23.587, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 135000, "episodes_total": 131, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-47-42", "timestamp": 1606319262, "training_iteration": 68, "time_this_iter_s": 7.119751453399658, "time_total_s": 532.893173456192, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def73b00>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def62630>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 532.893173456192, "timesteps_since_restore": 135000, "iterations_since_restore": 68}
{"episode_reward_max": 626.0, "episode_reward_min": 372.0, "episode_reward_mean": 515.88, "episode_len_mean": 1000.0, "episodes_this_iter": 4, "policy_reward_mean": {"agent-0": 97.19, "agent-1": 100.66, "agent-2": 106.2, "agent-3": 101.0, "agent-4": 110.83}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 137000, "num_steps_sampled": 137000, "wait_time_ms": 9.115, "apply_time_ms": 8.044, "dispatch_time_ms": 24.149, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 137000, "episodes_total": 135, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-47-50", "timestamp": 1606319270, "training_iteration": 69, "time_this_iter_s": 7.109781503677368, "time_total_s": 540.0029549598694, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def8d7f0>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def628d0>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 540.0029549598694, "timesteps_since_restore": 137000, "iterations_since_restore": 69}
{"episode_reward_max": 626.0, "episode_reward_min": 372.0, "episode_reward_mean": 515.24, "episode_len_mean": 1000.0, "episodes_this_iter": 1, "policy_reward_mean": {"agent-0": 96.76, "agent-1": 100.32, "agent-2": 106.34, "agent-3": 100.97, "agent-4": 110.85}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 139000, "num_steps_sampled": 139000, "wait_time_ms": 11.012, "apply_time_ms": 8.204, "dispatch_time_ms": 24.166, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 139000, "episodes_total": 136, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-47-57", "timestamp": 1606319277, "training_iteration": 70, "time_this_iter_s": 7.142435312271118, "time_total_s": 547.1453902721405, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def739e8>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def87f28>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 547.1453902721405, "timesteps_since_restore": 139000, "iterations_since_restore": 70}
{"episode_reward_max": 626.0, "episode_reward_min": 372.0, "episode_reward_mean": 514.94, "episode_len_mean": 1000.0, "episodes_this_iter": 1, "policy_reward_mean": {"agent-0": 97.05, "agent-1": 100.11, "agent-2": 105.8, "agent-3": 101.04, "agent-4": 110.94}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 141000, "num_steps_sampled": 141000, "wait_time_ms": 8.036, "apply_time_ms": 8.082, "dispatch_time_ms": 24.232, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 141000, "episodes_total": 137, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-48-04", "timestamp": 1606319284, "training_iteration": 71, "time_this_iter_s": 7.118685722351074, "time_total_s": 554.2640759944916, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def8d208>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def8d9b0>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 554.2640759944916, "timesteps_since_restore": 141000, "iterations_since_restore": 71}
{"episode_reward_max": 626.0, "episode_reward_min": 372.0, "episode_reward_mean": 514.6, "episode_len_mean": 1000.0, "episodes_this_iter": 4, "policy_reward_mean": {"agent-0": 98.69, "agent-1": 100.4, "agent-2": 105.36, "agent-3": 100.44, "agent-4": 109.71}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 143000, "num_steps_sampled": 143000, "wait_time_ms": 4.016, "apply_time_ms": 8.315, "dispatch_time_ms": 25.749, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 143000, "episodes_total": 141, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-48-11", "timestamp": 1606319291, "training_iteration": 72, "time_this_iter_s": 7.0528059005737305, "time_total_s": 561.3168818950653, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def75630>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def87828>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 561.3168818950653, "timesteps_since_restore": 143000, "iterations_since_restore": 72}
{"episode_reward_max": 626.0, "episode_reward_min": 372.0, "episode_reward_mean": 514.8, "episode_len_mean": 1000.0, "episodes_this_iter": 1, "policy_reward_mean": {"agent-0": 98.97, "agent-1": 100.06, "agent-2": 105.34, "agent-3": 100.86, "agent-4": 109.57}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 145000, "num_steps_sampled": 145000, "wait_time_ms": 8.137, "apply_time_ms": 8.178, "dispatch_time_ms": 23.723, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 145000, "episodes_total": 142, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-48-18", "timestamp": 1606319298, "training_iteration": 73, "time_this_iter_s": 7.051841497421265, "time_total_s": 568.3687233924866, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def62cf8>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def87c50>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 568.3687233924866, "timesteps_since_restore": 145000, "iterations_since_restore": 73}
{"episode_reward_max": 626.0, "episode_reward_min": 372.0, "episode_reward_mean": 514.55, "episode_len_mean": 1000.0, "episodes_this_iter": 1, "policy_reward_mean": {"agent-0": 99.04, "agent-1": 99.66, "agent-2": 105.29, "agent-3": 100.89, "agent-4": 109.67}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 147000, "num_steps_sampled": 147000, "wait_time_ms": 6.42, "apply_time_ms": 8.205, "dispatch_time_ms": 25.393, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 147000, "episodes_total": 143, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-48-25", "timestamp": 1606319305, "training_iteration": 74, "time_this_iter_s": 7.214036703109741, "time_total_s": 575.5827600955963, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa340eb4160>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def87da0>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 575.5827600955963, "timesteps_since_restore": 147000, "iterations_since_restore": 74}
{"episode_reward_max": 626.0, "episode_reward_min": 372.0, "episode_reward_mean": 517.26, "episode_len_mean": 1000.0, "episodes_this_iter": 4, "policy_reward_mean": {"agent-0": 100.04, "agent-1": 100.15, "agent-2": 105.17, "agent-3": 100.28, "agent-4": 111.62}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 149000, "num_steps_sampled": 149000, "wait_time_ms": 7.635, "apply_time_ms": 8.012, "dispatch_time_ms": 23.408, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 149000, "episodes_total": 147, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-48-32", "timestamp": 1606319312, "training_iteration": 75, "time_this_iter_s": 6.990210771560669, "time_total_s": 582.572970867157, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def8d400>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def87c18>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 582.572970867157, "timesteps_since_restore": 149000, "iterations_since_restore": 75}
{"episode_reward_max": 626.0, "episode_reward_min": 372.0, "episode_reward_mean": 516.68, "episode_len_mean": 1000.0, "episodes_this_iter": 1, "policy_reward_mean": {"agent-0": 100.54, "agent-1": 100.0, "agent-2": 104.87, "agent-3": 100.03, "agent-4": 111.24}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 151000, "num_steps_sampled": 151000, "wait_time_ms": 10.263, "apply_time_ms": 8.07, "dispatch_time_ms": 25.395, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 151000, "episodes_total": 148, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-48-39", "timestamp": 1606319319, "training_iteration": 76, "time_this_iter_s": 7.099279403686523, "time_total_s": 589.6722502708435, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def75588>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def872b0>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 589.6722502708435, "timesteps_since_restore": 151000, "iterations_since_restore": 76}
{"episode_reward_max": 626.0, "episode_reward_min": 372.0, "episode_reward_mean": 516.53, "episode_len_mean": 1000.0, "episodes_this_iter": 1, "policy_reward_mean": {"agent-0": 100.98, "agent-1": 100.2, "agent-2": 104.32, "agent-3": 100.14, "agent-4": 110.89}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 153000, "num_steps_sampled": 153000, "wait_time_ms": 7.121, "apply_time_ms": 8.32, "dispatch_time_ms": 27.009, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 153000, "episodes_total": 149, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-48-47", "timestamp": 1606319327, "training_iteration": 77, "time_this_iter_s": 7.214529037475586, "time_total_s": 596.8867793083191, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def624a8>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def87a90>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 596.8867793083191, "timesteps_since_restore": 153000, "iterations_since_restore": 77}
{"episode_reward_max": 626.0, "episode_reward_min": 388.0, "episode_reward_mean": 517.3, "episode_len_mean": 1000.0, "episodes_this_iter": 4, "policy_reward_mean": {"agent-0": 100.54, "agent-1": 100.49, "agent-2": 104.22, "agent-3": 100.23, "agent-4": 111.82}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 155000, "num_steps_sampled": 155000, "wait_time_ms": 43.595, "apply_time_ms": 7.718, "dispatch_time_ms": 26.341, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 155000, "episodes_total": 153, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-48-54", "timestamp": 1606319334, "training_iteration": 78, "time_this_iter_s": 7.385396242141724, "time_total_s": 604.2721755504608, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def73ba8>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def872e8>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 604.2721755504608, "timesteps_since_restore": 155000, "iterations_since_restore": 78}
{"episode_reward_max": 626.0, "episode_reward_min": 388.0, "episode_reward_mean": 518.27, "episode_len_mean": 1000.0, "episodes_this_iter": 1, "policy_reward_mean": {"agent-0": 100.64, "agent-1": 100.32, "agent-2": 104.14, "agent-3": 100.8, "agent-4": 112.37}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 157000, "num_steps_sampled": 157000, "wait_time_ms": 6.885, "apply_time_ms": 8.518, "dispatch_time_ms": 25.325, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 157000, "episodes_total": 154, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-49-01", "timestamp": 1606319341, "training_iteration": 79, "time_this_iter_s": 7.10385799407959, "time_total_s": 611.3760335445404, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def62978>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def87ac8>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 611.3760335445404, "timesteps_since_restore": 157000, "iterations_since_restore": 79}
{"episode_reward_max": 636.0, "episode_reward_min": 388.0, "episode_reward_mean": 517.98, "episode_len_mean": 1000.0, "episodes_this_iter": 3, "policy_reward_mean": {"agent-0": 101.82, "agent-1": 100.3, "agent-2": 103.96, "agent-3": 99.69, "agent-4": 112.21}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 159000, "num_steps_sampled": 159000, "wait_time_ms": 8.432, "apply_time_ms": 8.005, "dispatch_time_ms": 22.934, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 159000, "episodes_total": 157, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-49-08", "timestamp": 1606319348, "training_iteration": 80, "time_this_iter_s": 7.068211317062378, "time_total_s": 618.4442448616028, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def872e8>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def874a8>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 618.4442448616028, "timesteps_since_restore": 159000, "iterations_since_restore": 80}
{"episode_reward_max": 636.0, "episode_reward_min": 388.0, "episode_reward_mean": 517.87, "episode_len_mean": 1000.0, "episodes_this_iter": 2, "policy_reward_mean": {"agent-0": 102.82, "agent-1": 100.18, "agent-2": 103.26, "agent-3": 99.56, "agent-4": 112.05}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 161000, "num_steps_sampled": 161000, "wait_time_ms": 8.189, "apply_time_ms": 7.869, "dispatch_time_ms": 24.122, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 161000, "episodes_total": 159, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-49-15", "timestamp": 1606319355, "training_iteration": 81, "time_this_iter_s": 7.083815097808838, "time_total_s": 625.5280599594116, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def37f28>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def62c18>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 625.5280599594116, "timesteps_since_restore": 161000, "iterations_since_restore": 81}
{"episode_reward_max": 636.0, "episode_reward_min": 388.0, "episode_reward_mean": 517.64, "episode_len_mean": 1000.0, "episodes_this_iter": 1, "policy_reward_mean": {"agent-0": 103.24, "agent-1": 99.69, "agent-2": 102.93, "agent-3": 99.31, "agent-4": 112.47}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 163000, "num_steps_sampled": 163000, "wait_time_ms": 8.648, "apply_time_ms": 7.428, "dispatch_time_ms": 24.115, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 163000, "episodes_total": 160, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-49-23", "timestamp": 1606319363, "training_iteration": 82, "time_this_iter_s": 7.083327293395996, "time_total_s": 632.6113872528076, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def871d0>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def87cf8>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 632.6113872528076, "timesteps_since_restore": 163000, "iterations_since_restore": 82}
{"episode_reward_max": 636.0, "episode_reward_min": 388.0, "episode_reward_mean": 518.02, "episode_len_mean": 1000.0, "episodes_this_iter": 3, "policy_reward_mean": {"agent-0": 103.2, "agent-1": 99.39, "agent-2": 103.34, "agent-3": 99.19, "agent-4": 112.9}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 165000, "num_steps_sampled": 165000, "wait_time_ms": 9.057, "apply_time_ms": 7.485, "dispatch_time_ms": 23.887, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 165000, "episodes_total": 163, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-49-30", "timestamp": 1606319370, "training_iteration": 83, "time_this_iter_s": 7.144495487213135, "time_total_s": 639.7558827400208, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def62978>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def87e80>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 639.7558827400208, "timesteps_since_restore": 165000, "iterations_since_restore": 83}
{"episode_reward_max": 636.0, "episode_reward_min": 419.0, "episode_reward_mean": 519.78, "episode_len_mean": 1000.0, "episodes_this_iter": 2, "policy_reward_mean": {"agent-0": 103.2, "agent-1": 98.78, "agent-2": 104.7, "agent-3": 99.35, "agent-4": 113.75}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 167000, "num_steps_sampled": 167000, "wait_time_ms": 6.676, "apply_time_ms": 7.006, "dispatch_time_ms": 25.457, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 167000, "episodes_total": 165, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-49-37", "timestamp": 1606319377, "training_iteration": 84, "time_this_iter_s": 7.0892415046691895, "time_total_s": 646.8451242446899, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def875f8>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def877f0>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 646.8451242446899, "timesteps_since_restore": 167000, "iterations_since_restore": 84}
{"episode_reward_max": 636.0, "episode_reward_min": 419.0, "episode_reward_mean": 518.76, "episode_len_mean": 1000.0, "episodes_this_iter": 1, "policy_reward_mean": {"agent-0": 103.18, "agent-1": 98.24, "agent-2": 104.79, "agent-3": 98.69, "agent-4": 113.86}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 169000, "num_steps_sampled": 169000, "wait_time_ms": 9.139, "apply_time_ms": 7.609, "dispatch_time_ms": 22.884, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 169000, "episodes_total": 166, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-49-44", "timestamp": 1606319384, "training_iteration": 85, "time_this_iter_s": 7.028403043746948, "time_total_s": 653.8735272884369, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def75be0>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def75e48>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 653.8735272884369, "timesteps_since_restore": 169000, "iterations_since_restore": 85}
{"episode_reward_max": 636.0, "episode_reward_min": 419.0, "episode_reward_mean": 518.85, "episode_len_mean": 1000.0, "episodes_this_iter": 3, "policy_reward_mean": {"agent-0": 102.82, "agent-1": 98.81, "agent-2": 104.4, "agent-3": 98.63, "agent-4": 114.19}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 171000, "num_steps_sampled": 171000, "wait_time_ms": 7.4, "apply_time_ms": 8.818, "dispatch_time_ms": 24.107, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 171000, "episodes_total": 169, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-49-51", "timestamp": 1606319391, "training_iteration": 86, "time_this_iter_s": 7.033712863922119, "time_total_s": 660.907240152359, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def87240>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def87e80>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 660.907240152359, "timesteps_since_restore": 171000, "iterations_since_restore": 86}
{"episode_reward_max": 636.0, "episode_reward_min": 419.0, "episode_reward_mean": 518.4, "episode_len_mean": 1000.0, "episodes_this_iter": 1, "policy_reward_mean": {"agent-0": 102.99, "agent-1": 98.94, "agent-2": 104.24, "agent-3": 98.39, "agent-4": 113.84}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 173000, "num_steps_sampled": 173000, "wait_time_ms": 8.375, "apply_time_ms": 7.425, "dispatch_time_ms": 22.324, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 173000, "episodes_total": 170, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-49-58", "timestamp": 1606319398, "training_iteration": 87, "time_this_iter_s": 7.0140910148620605, "time_total_s": 667.9213311672211, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def75da0>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def8d128>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 667.9213311672211, "timesteps_since_restore": 173000, "iterations_since_restore": 87}
{"episode_reward_max": 636.0, "episode_reward_min": 419.0, "episode_reward_mean": 519.24, "episode_len_mean": 1000.0, "episodes_this_iter": 2, "policy_reward_mean": {"agent-0": 103.47, "agent-1": 99.22, "agent-2": 104.0, "agent-3": 98.99, "agent-4": 113.56}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 175000, "num_steps_sampled": 175000, "wait_time_ms": 8.06, "apply_time_ms": 8.22, "dispatch_time_ms": 22.614, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 175000, "episodes_total": 172, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-50-05", "timestamp": 1606319405, "training_iteration": 88, "time_this_iter_s": 7.148318767547607, "time_total_s": 675.0696499347687, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def877f0>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def8dcf8>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 675.0696499347687, "timesteps_since_restore": 175000, "iterations_since_restore": 88}
{"episode_reward_max": 636.0, "episode_reward_min": 419.0, "episode_reward_mean": 519.87, "episode_len_mean": 1000.0, "episodes_this_iter": 3, "policy_reward_mean": {"agent-0": 103.39, "agent-1": 99.34, "agent-2": 103.93, "agent-3": 99.0, "agent-4": 114.21}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 177000, "num_steps_sampled": 177000, "wait_time_ms": 7.826, "apply_time_ms": 7.716, "dispatch_time_ms": 23.417, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 177000, "episodes_total": 175, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-50-12", "timestamp": 1606319412, "training_iteration": 89, "time_this_iter_s": 7.013501405715942, "time_total_s": 682.0831513404846, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def753c8>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def8dfd0>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 682.0831513404846, "timesteps_since_restore": 177000, "iterations_since_restore": 89}
{"episode_reward_max": 636.0, "episode_reward_min": 419.0, "episode_reward_mean": 520.07, "episode_len_mean": 1000.0, "episodes_this_iter": 1, "policy_reward_mean": {"agent-0": 104.0, "agent-1": 99.46, "agent-2": 103.85, "agent-3": 98.93, "agent-4": 113.83}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 179000, "num_steps_sampled": 179000, "wait_time_ms": 8.554, "apply_time_ms": 7.443, "dispatch_time_ms": 24.461, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 179000, "episodes_total": 176, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-50-19", "timestamp": 1606319419, "training_iteration": 90, "time_this_iter_s": 7.001103639602661, "time_total_s": 689.0842549800873, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def73160>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def62e10>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 689.0842549800873, "timesteps_since_restore": 179000, "iterations_since_restore": 90}
{"episode_reward_max": 636.0, "episode_reward_min": 419.0, "episode_reward_mean": 521.12, "episode_len_mean": 1000.0, "episodes_this_iter": 2, "policy_reward_mean": {"agent-0": 104.78, "agent-1": 99.89, "agent-2": 104.04, "agent-3": 98.58, "agent-4": 113.83}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 181000, "num_steps_sampled": 181000, "wait_time_ms": 8.223, "apply_time_ms": 7.079, "dispatch_time_ms": 23.764, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 181000, "episodes_total": 178, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-50-26", "timestamp": 1606319426, "training_iteration": 91, "time_this_iter_s": 7.142856121063232, "time_total_s": 696.2271111011505, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def8dfd0>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def8de10>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 696.2271111011505, "timesteps_since_restore": 181000, "iterations_since_restore": 91}
{"episode_reward_max": 636.0, "episode_reward_min": 419.0, "episode_reward_mean": 522.43, "episode_len_mean": 1000.0, "episodes_this_iter": 3, "policy_reward_mean": {"agent-0": 104.71, "agent-1": 99.86, "agent-2": 104.88, "agent-3": 98.84, "agent-4": 114.14}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 183000, "num_steps_sampled": 183000, "wait_time_ms": 8.53, "apply_time_ms": 7.122, "dispatch_time_ms": 23.458, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 183000, "episodes_total": 181, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-50-33", "timestamp": 1606319433, "training_iteration": 92, "time_this_iter_s": 7.05537748336792, "time_total_s": 703.2824885845184, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def87080>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def62320>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 703.2824885845184, "timesteps_since_restore": 183000, "iterations_since_restore": 92}
{"episode_reward_max": 636.0, "episode_reward_min": 419.0, "episode_reward_mean": 522.44, "episode_len_mean": 1000.0, "episodes_this_iter": 1, "policy_reward_mean": {"agent-0": 105.31, "agent-1": 99.97, "agent-2": 104.12, "agent-3": 98.99, "agent-4": 114.05}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 185000, "num_steps_sampled": 185000, "wait_time_ms": 6.631, "apply_time_ms": 7.529, "dispatch_time_ms": 24.404, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 185000, "episodes_total": 182, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-50-40", "timestamp": 1606319440, "training_iteration": 93, "time_this_iter_s": 7.02184796333313, "time_total_s": 710.3043365478516, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def755f8>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def75748>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 710.3043365478516, "timesteps_since_restore": 185000, "iterations_since_restore": 93}
{"episode_reward_max": 636.0, "episode_reward_min": 419.0, "episode_reward_mean": 522.16, "episode_len_mean": 1000.0, "episodes_this_iter": 2, "policy_reward_mean": {"agent-0": 105.57, "agent-1": 99.74, "agent-2": 104.51, "agent-3": 98.62, "agent-4": 113.72}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 187000, "num_steps_sampled": 187000, "wait_time_ms": 6.84, "apply_time_ms": 8.381, "dispatch_time_ms": 23.498, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 187000, "episodes_total": 184, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-50-47", "timestamp": 1606319447, "training_iteration": 94, "time_this_iter_s": 6.982227325439453, "time_total_s": 717.286563873291, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def879b0>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def87208>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 717.286563873291, "timesteps_since_restore": 187000, "iterations_since_restore": 94}
{"episode_reward_max": 636.0, "episode_reward_min": 419.0, "episode_reward_mean": 523.93, "episode_len_mean": 1000.0, "episodes_this_iter": 3, "policy_reward_mean": {"agent-0": 106.59, "agent-1": 99.41, "agent-2": 104.76, "agent-3": 98.67, "agent-4": 114.5}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 189000, "num_steps_sampled": 189000, "wait_time_ms": 7.218, "apply_time_ms": 8.712, "dispatch_time_ms": 23.072, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 189000, "episodes_total": 187, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-50-54", "timestamp": 1606319454, "training_iteration": 95, "time_this_iter_s": 7.00628924369812, "time_total_s": 724.2928531169891, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def8dfd0>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def8de80>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 724.2928531169891, "timesteps_since_restore": 189000, "iterations_since_restore": 95}
{"episode_reward_max": 636.0, "episode_reward_min": 419.0, "episode_reward_mean": 524.39, "episode_len_mean": 1000.0, "episodes_this_iter": 1, "policy_reward_mean": {"agent-0": 106.57, "agent-1": 99.42, "agent-2": 105.56, "agent-3": 98.12, "agent-4": 114.72}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 191000, "num_steps_sampled": 191000, "wait_time_ms": 4.858, "apply_time_ms": 7.987, "dispatch_time_ms": 22.843, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 191000, "episodes_total": 188, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-51-01", "timestamp": 1606319461, "training_iteration": 96, "time_this_iter_s": 6.9441845417022705, "time_total_s": 731.2370376586914, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def8d4e0>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def62ac8>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 731.2370376586914, "timesteps_since_restore": 191000, "iterations_since_restore": 96}
{"episode_reward_max": 636.0, "episode_reward_min": 419.0, "episode_reward_mean": 523.54, "episode_len_mean": 1000.0, "episodes_this_iter": 2, "policy_reward_mean": {"agent-0": 106.7, "agent-1": 99.62, "agent-2": 105.17, "agent-3": 97.5, "agent-4": 114.55}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 193000, "num_steps_sampled": 193000, "wait_time_ms": 8.912, "apply_time_ms": 7.106, "dispatch_time_ms": 23.746, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 193000, "episodes_total": 190, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-51-08", "timestamp": 1606319468, "training_iteration": 97, "time_this_iter_s": 6.930448293685913, "time_total_s": 738.1674859523773, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def75080>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def62978>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 738.1674859523773, "timesteps_since_restore": 193000, "iterations_since_restore": 97}
{"episode_reward_max": 636.0, "episode_reward_min": 419.0, "episode_reward_mean": 523.97, "episode_len_mean": 1000.0, "episodes_this_iter": 3, "policy_reward_mean": {"agent-0": 106.83, "agent-1": 100.17, "agent-2": 105.55, "agent-3": 96.5, "agent-4": 114.92}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 195000, "num_steps_sampled": 195000, "wait_time_ms": 6.206, "apply_time_ms": 7.196, "dispatch_time_ms": 24.393, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 195000, "episodes_total": 193, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-51-15", "timestamp": 1606319475, "training_iteration": 98, "time_this_iter_s": 6.980390310287476, "time_total_s": 745.1478762626648, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def870f0>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def87f98>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 745.1478762626648, "timesteps_since_restore": 195000, "iterations_since_restore": 98}
{"episode_reward_max": 636.0, "episode_reward_min": 419.0, "episode_reward_mean": 524.14, "episode_len_mean": 1000.0, "episodes_this_iter": 2, "policy_reward_mean": {"agent-0": 106.86, "agent-1": 100.43, "agent-2": 104.38, "agent-3": 97.43, "agent-4": 115.04}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 197000, "num_steps_sampled": 197000, "wait_time_ms": 8.083, "apply_time_ms": 7.837, "dispatch_time_ms": 24.328, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 197000, "episodes_total": 195, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-51-22", "timestamp": 1606319482, "training_iteration": 99, "time_this_iter_s": 7.012069225311279, "time_total_s": 752.1599454879761, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def8d400>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def62cf8>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 752.1599454879761, "timesteps_since_restore": 197000, "iterations_since_restore": 99}
{"episode_reward_max": 636.0, "episode_reward_min": 419.0, "episode_reward_mean": 524.91, "episode_len_mean": 1000.0, "episodes_this_iter": 1, "policy_reward_mean": {"agent-0": 107.25, "agent-1": 100.69, "agent-2": 104.33, "agent-3": 97.46, "agent-4": 115.18}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 199000, "num_steps_sampled": 199000, "wait_time_ms": 9.524, "apply_time_ms": 7.939, "dispatch_time_ms": 21.666, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 199000, "episodes_total": 196, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-51-30", "timestamp": 1606319490, "training_iteration": 100, "time_this_iter_s": 7.13242506980896, "time_total_s": 759.292370557785, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def62eb8>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def75d68>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 759.292370557785, "timesteps_since_restore": 199000, "iterations_since_restore": 100}
{"episode_reward_max": 636.0, "episode_reward_min": 411.0, "episode_reward_mean": 524.03, "episode_len_mean": 1000.0, "episodes_this_iter": 3, "policy_reward_mean": {"agent-0": 107.33, "agent-1": 100.74, "agent-2": 103.29, "agent-3": 97.81, "agent-4": 114.86}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 201000, "num_steps_sampled": 201000, "wait_time_ms": 7.038, "apply_time_ms": 7.505, "dispatch_time_ms": 21.918, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 201000, "episodes_total": 199, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-51-37", "timestamp": 1606319497, "training_iteration": 101, "time_this_iter_s": 6.990160226821899, "time_total_s": 766.2825307846069, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def75ac8>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def73320>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 766.2825307846069, "timesteps_since_restore": 201000, "iterations_since_restore": 101}
{"episode_reward_max": 636.0, "episode_reward_min": 411.0, "episode_reward_mean": 524.06, "episode_len_mean": 1000.0, "episodes_this_iter": 2, "policy_reward_mean": {"agent-0": 108.39, "agent-1": 100.95, "agent-2": 102.34, "agent-3": 97.49, "agent-4": 114.89}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 203000, "num_steps_sampled": 203000, "wait_time_ms": 7.613, "apply_time_ms": 7.302, "dispatch_time_ms": 23.607, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 203000, "episodes_total": 201, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-51-44", "timestamp": 1606319504, "training_iteration": 102, "time_this_iter_s": 7.0352396965026855, "time_total_s": 773.3177704811096, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def87ac8>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def8d0b8>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 773.3177704811096, "timesteps_since_restore": 203000, "iterations_since_restore": 102}
{"episode_reward_max": 636.0, "episode_reward_min": 411.0, "episode_reward_mean": 524.39, "episode_len_mean": 1000.0, "episodes_this_iter": 1, "policy_reward_mean": {"agent-0": 108.46, "agent-1": 101.26, "agent-2": 102.36, "agent-3": 97.23, "agent-4": 115.08}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 205000, "num_steps_sampled": 205000, "wait_time_ms": 5.204, "apply_time_ms": 8.403, "dispatch_time_ms": 24.74, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 205000, "episodes_total": 202, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-51-51", "timestamp": 1606319511, "training_iteration": 103, "time_this_iter_s": 6.985867977142334, "time_total_s": 780.303638458252, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def8d9e8>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def73160>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 780.303638458252, "timesteps_since_restore": 205000, "iterations_since_restore": 103}
{"episode_reward_max": 636.0, "episode_reward_min": 411.0, "episode_reward_mean": 523.3, "episode_len_mean": 1000.0, "episodes_this_iter": 3, "policy_reward_mean": {"agent-0": 109.7, "agent-1": 101.11, "agent-2": 101.34, "agent-3": 96.61, "agent-4": 114.54}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 207000, "num_steps_sampled": 207000, "wait_time_ms": 5.635, "apply_time_ms": 7.261, "dispatch_time_ms": 23.793, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 207000, "episodes_total": 205, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-51-58", "timestamp": 1606319518, "training_iteration": 104, "time_this_iter_s": 6.996301651000977, "time_total_s": 787.2999401092529, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def875f8>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def87ba8>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 787.2999401092529, "timesteps_since_restore": 207000, "iterations_since_restore": 104}
{"episode_reward_max": 636.0, "episode_reward_min": 411.0, "episode_reward_mean": 522.51, "episode_len_mean": 1000.0, "episodes_this_iter": 1, "policy_reward_mean": {"agent-0": 109.66, "agent-1": 101.33, "agent-2": 100.97, "agent-3": 96.11, "agent-4": 114.44}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 209000, "num_steps_sampled": 209000, "wait_time_ms": 8.888, "apply_time_ms": 7.678, "dispatch_time_ms": 22.858, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 209000, "episodes_total": 206, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-52-05", "timestamp": 1606319525, "training_iteration": 105, "time_this_iter_s": 7.115656852722168, "time_total_s": 794.4155969619751, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def75128>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def757b8>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 794.4155969619751, "timesteps_since_restore": 209000, "iterations_since_restore": 105}
{"episode_reward_max": 636.0, "episode_reward_min": 411.0, "episode_reward_mean": 523.89, "episode_len_mean": 1000.0, "episodes_this_iter": 2, "policy_reward_mean": {"agent-0": 110.27, "agent-1": 101.45, "agent-2": 100.96, "agent-3": 96.53, "agent-4": 114.68}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 211000, "num_steps_sampled": 211000, "wait_time_ms": 11.524, "apply_time_ms": 7.507, "dispatch_time_ms": 23.835, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 211000, "episodes_total": 208, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-52-12", "timestamp": 1606319532, "training_iteration": 106, "time_this_iter_s": 7.012854814529419, "time_total_s": 801.4284517765045, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def87c88>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def8df60>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 801.4284517765045, "timesteps_since_restore": 211000, "iterations_since_restore": 106}
{"episode_reward_max": 636.0, "episode_reward_min": 411.0, "episode_reward_mean": 526.26, "episode_len_mean": 1000.0, "episodes_this_iter": 3, "policy_reward_mean": {"agent-0": 110.77, "agent-1": 101.62, "agent-2": 101.26, "agent-3": 96.88, "agent-4": 115.73}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 213000, "num_steps_sampled": 213000, "wait_time_ms": 9.162, "apply_time_ms": 7.716, "dispatch_time_ms": 23.11, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 213000, "episodes_total": 211, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-52-19", "timestamp": 1606319539, "training_iteration": 107, "time_this_iter_s": 7.077277421951294, "time_total_s": 808.5057291984558, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def8de48>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def73ef0>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 808.5057291984558, "timesteps_since_restore": 213000, "iterations_since_restore": 107}
{"episode_reward_max": 636.0, "episode_reward_min": 411.0, "episode_reward_mean": 526.88, "episode_len_mean": 1000.0, "episodes_this_iter": 1, "policy_reward_mean": {"agent-0": 110.79, "agent-1": 101.81, "agent-2": 100.72, "agent-3": 97.28, "agent-4": 116.28}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 215000, "num_steps_sampled": 215000, "wait_time_ms": 7.817, "apply_time_ms": 7.262, "dispatch_time_ms": 24.426, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 215000, "episodes_total": 212, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-52-26", "timestamp": 1606319546, "training_iteration": 108, "time_this_iter_s": 7.102491617202759, "time_total_s": 815.6082208156586, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def87630>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def873c8>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 815.6082208156586, "timesteps_since_restore": 215000, "iterations_since_restore": 108}
{"episode_reward_max": 636.0, "episode_reward_min": 411.0, "episode_reward_mean": 527.03, "episode_len_mean": 1000.0, "episodes_this_iter": 2, "policy_reward_mean": {"agent-0": 110.92, "agent-1": 101.09, "agent-2": 100.82, "agent-3": 97.74, "agent-4": 116.46}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 217000, "num_steps_sampled": 217000, "wait_time_ms": 5.712, "apply_time_ms": 8.282, "dispatch_time_ms": 25.651, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 217000, "episodes_total": 214, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-52-33", "timestamp": 1606319553, "training_iteration": 109, "time_this_iter_s": 7.080581903457642, "time_total_s": 822.6888027191162, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def75320>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def75400>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 822.6888027191162, "timesteps_since_restore": 217000, "iterations_since_restore": 109}
{"episode_reward_max": 636.0, "episode_reward_min": 411.0, "episode_reward_mean": 527.91, "episode_len_mean": 1000.0, "episodes_this_iter": 3, "policy_reward_mean": {"agent-0": 111.63, "agent-1": 101.35, "agent-2": 100.55, "agent-3": 97.63, "agent-4": 116.75}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 219000, "num_steps_sampled": 219000, "wait_time_ms": 7.601, "apply_time_ms": 9.883, "dispatch_time_ms": 23.4, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 219000, "episodes_total": 217, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-52-40", "timestamp": 1606319560, "training_iteration": 110, "time_this_iter_s": 6.955915212631226, "time_total_s": 829.6447179317474, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def8de80>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def93a90>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 829.6447179317474, "timesteps_since_restore": 219000, "iterations_since_restore": 110}
{"episode_reward_max": 636.0, "episode_reward_min": 411.0, "episode_reward_mean": 527.46, "episode_len_mean": 1000.0, "episodes_this_iter": 1, "policy_reward_mean": {"agent-0": 111.4, "agent-1": 101.1, "agent-2": 100.48, "agent-3": 97.67, "agent-4": 116.81}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 221000, "num_steps_sampled": 221000, "wait_time_ms": 7.968, "apply_time_ms": 7.726, "dispatch_time_ms": 24.783, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 221000, "episodes_total": 218, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-52-47", "timestamp": 1606319567, "training_iteration": 111, "time_this_iter_s": 6.993431091308594, "time_total_s": 836.638149023056, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def73ef0>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def93e48>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 836.638149023056, "timesteps_since_restore": 221000, "iterations_since_restore": 111}
{"episode_reward_max": 636.0, "episode_reward_min": 411.0, "episode_reward_mean": 526.43, "episode_len_mean": 1000.0, "episodes_this_iter": 2, "policy_reward_mean": {"agent-0": 111.75, "agent-1": 101.09, "agent-2": 99.57, "agent-3": 96.78, "agent-4": 117.24}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 223000, "num_steps_sampled": 223000, "wait_time_ms": 8.719, "apply_time_ms": 7.67, "dispatch_time_ms": 23.862, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 223000, "episodes_total": 220, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-52-54", "timestamp": 1606319574, "training_iteration": 112, "time_this_iter_s": 7.049931049346924, "time_total_s": 843.688080072403, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def75400>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def93ba8>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 843.688080072403, "timesteps_since_restore": 223000, "iterations_since_restore": 112}
{"episode_reward_max": 636.0, "episode_reward_min": 411.0, "episode_reward_mean": 525.95, "episode_len_mean": 1000.0, "episodes_this_iter": 3, "policy_reward_mean": {"agent-0": 112.09, "agent-1": 100.98, "agent-2": 99.82, "agent-3": 95.38, "agent-4": 117.68}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 225000, "num_steps_sampled": 225000, "wait_time_ms": 8.858, "apply_time_ms": 7.482, "dispatch_time_ms": 24.105, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 225000, "episodes_total": 223, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-53-01", "timestamp": 1606319581, "training_iteration": 113, "time_this_iter_s": 6.991374254226685, "time_total_s": 850.6794543266296, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def73240>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def93cc0>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 850.6794543266296, "timesteps_since_restore": 225000, "iterations_since_restore": 113}
{"episode_reward_max": 636.0, "episode_reward_min": 411.0, "episode_reward_mean": 526.21, "episode_len_mean": 1000.0, "episodes_this_iter": 1, "policy_reward_mean": {"agent-0": 112.49, "agent-1": 101.14, "agent-2": 99.66, "agent-3": 94.8, "agent-4": 118.12}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 227000, "num_steps_sampled": 227000, "wait_time_ms": 7.757, "apply_time_ms": 8.347, "dispatch_time_ms": 22.868, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 227000, "episodes_total": 224, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-53-08", "timestamp": 1606319588, "training_iteration": 114, "time_this_iter_s": 7.076400518417358, "time_total_s": 857.755854845047, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def8df60>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def937f0>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 857.755854845047, "timesteps_since_restore": 227000, "iterations_since_restore": 114}
{"episode_reward_max": 636.0, "episode_reward_min": 411.0, "episode_reward_mean": 526.38, "episode_len_mean": 1000.0, "episodes_this_iter": 2, "policy_reward_mean": {"agent-0": 112.98, "agent-1": 100.62, "agent-2": 100.44, "agent-3": 93.99, "agent-4": 118.35}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 229000, "num_steps_sampled": 229000, "wait_time_ms": 9.223, "apply_time_ms": 7.409, "dispatch_time_ms": 20.931, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 229000, "episodes_total": 226, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-53-16", "timestamp": 1606319596, "training_iteration": 115, "time_this_iter_s": 7.114952325820923, "time_total_s": 864.8708071708679, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def75588>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def934e0>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 864.8708071708679, "timesteps_since_restore": 229000, "iterations_since_restore": 115}
{"episode_reward_max": 636.0, "episode_reward_min": 411.0, "episode_reward_mean": 527.18, "episode_len_mean": 1000.0, "episodes_this_iter": 3, "policy_reward_mean": {"agent-0": 113.66, "agent-1": 100.95, "agent-2": 100.81, "agent-3": 93.74, "agent-4": 118.02}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 231000, "num_steps_sampled": 231000, "wait_time_ms": 8.003, "apply_time_ms": 6.733, "dispatch_time_ms": 24.009, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 231000, "episodes_total": 229, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-53-23", "timestamp": 1606319603, "training_iteration": 116, "time_this_iter_s": 6.993304252624512, "time_total_s": 871.8641114234924, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def8de10>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def93cf8>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 871.8641114234924, "timesteps_since_restore": 231000, "iterations_since_restore": 116}
{"episode_reward_max": 636.0, "episode_reward_min": 411.0, "episode_reward_mean": 526.96, "episode_len_mean": 1000.0, "episodes_this_iter": 1, "policy_reward_mean": {"agent-0": 113.91, "agent-1": 100.63, "agent-2": 100.92, "agent-3": 93.4, "agent-4": 118.1}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 233000, "num_steps_sampled": 233000, "wait_time_ms": 8.013, "apply_time_ms": 8.182, "dispatch_time_ms": 24.974, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 233000, "episodes_total": 230, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-53-30", "timestamp": 1606319610, "training_iteration": 117, "time_this_iter_s": 7.233196973800659, "time_total_s": 879.0973083972931, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def93b00>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def933c8>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 879.0973083972931, "timesteps_since_restore": 233000, "iterations_since_restore": 117}
{"episode_reward_max": 636.0, "episode_reward_min": 411.0, "episode_reward_mean": 526.76, "episode_len_mean": 1000.0, "episodes_this_iter": 2, "policy_reward_mean": {"agent-0": 114.54, "agent-1": 100.39, "agent-2": 100.72, "agent-3": 93.43, "agent-4": 117.68}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 235000, "num_steps_sampled": 235000, "wait_time_ms": 6.416, "apply_time_ms": 8.889, "dispatch_time_ms": 24.46, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 235000, "episodes_total": 232, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-53-37", "timestamp": 1606319617, "training_iteration": 118, "time_this_iter_s": 7.5436272621154785, "time_total_s": 886.6409356594086, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def93eb8>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def87be0>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 886.6409356594086, "timesteps_since_restore": 235000, "iterations_since_restore": 118}
{"episode_reward_max": 636.0, "episode_reward_min": 411.0, "episode_reward_mean": 526.12, "episode_len_mean": 1000.0, "episodes_this_iter": 3, "policy_reward_mean": {"agent-0": 114.61, "agent-1": 100.96, "agent-2": 100.56, "agent-3": 92.5, "agent-4": 117.49}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 237000, "num_steps_sampled": 237000, "wait_time_ms": 8.245, "apply_time_ms": 8.465, "dispatch_time_ms": 23.39, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 237000, "episodes_total": 235, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-53-44", "timestamp": 1606319624, "training_iteration": 119, "time_this_iter_s": 7.000113248825073, "time_total_s": 893.6410489082336, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def62cf8>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def73d30>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 893.6410489082336, "timesteps_since_restore": 237000, "iterations_since_restore": 119}
{"episode_reward_max": 636.0, "episode_reward_min": 411.0, "episode_reward_mean": 526.72, "episode_len_mean": 1000.0, "episodes_this_iter": 1, "policy_reward_mean": {"agent-0": 115.08, "agent-1": 101.18, "agent-2": 100.64, "agent-3": 92.22, "agent-4": 117.6}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 239000, "num_steps_sampled": 239000, "wait_time_ms": 7.6, "apply_time_ms": 7.228, "dispatch_time_ms": 24.968, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 239000, "episodes_total": 236, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-53-52", "timestamp": 1606319632, "training_iteration": 120, "time_this_iter_s": 7.120419979095459, "time_total_s": 900.7614688873291, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def932b0>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def93b38>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 900.7614688873291, "timesteps_since_restore": 239000, "iterations_since_restore": 120}
{"episode_reward_max": 636.0, "episode_reward_min": 411.0, "episode_reward_mean": 526.24, "episode_len_mean": 1000.0, "episodes_this_iter": 1, "policy_reward_mean": {"agent-0": 115.39, "agent-1": 100.9, "agent-2": 100.42, "agent-3": 92.01, "agent-4": 117.52}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 241000, "num_steps_sampled": 241000, "wait_time_ms": 7.42, "apply_time_ms": 7.822, "dispatch_time_ms": 22.215, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 241000, "episodes_total": 237, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-53-59", "timestamp": 1606319639, "training_iteration": 121, "time_this_iter_s": 7.054591655731201, "time_total_s": 907.8160605430603, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def87518>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def87f98>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 907.8160605430603, "timesteps_since_restore": 241000, "iterations_since_restore": 121}
{"episode_reward_max": 636.0, "episode_reward_min": 411.0, "episode_reward_mean": 525.85, "episode_len_mean": 1000.0, "episodes_this_iter": 4, "policy_reward_mean": {"agent-0": 114.96, "agent-1": 100.3, "agent-2": 99.87, "agent-3": 91.43, "agent-4": 119.29}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 243000, "num_steps_sampled": 243000, "wait_time_ms": 6.581, "apply_time_ms": 8.086, "dispatch_time_ms": 22.981, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 243000, "episodes_total": 241, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-54-06", "timestamp": 1606319646, "training_iteration": 122, "time_this_iter_s": 7.050961256027222, "time_total_s": 914.8670217990875, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def75860>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def93940>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 914.8670217990875, "timesteps_since_restore": 243000, "iterations_since_restore": 122}
{"episode_reward_max": 636.0, "episode_reward_min": 411.0, "episode_reward_mean": 525.3, "episode_len_mean": 1000.0, "episodes_this_iter": 1, "policy_reward_mean": {"agent-0": 114.78, "agent-1": 100.49, "agent-2": 99.74, "agent-3": 91.24, "agent-4": 119.05}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 245000, "num_steps_sampled": 245000, "wait_time_ms": 6.786, "apply_time_ms": 7.189, "dispatch_time_ms": 25.234, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 245000, "episodes_total": 242, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-54-13", "timestamp": 1606319653, "training_iteration": 123, "time_this_iter_s": 7.111002206802368, "time_total_s": 921.9780240058899, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def87f28>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def87cf8>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 921.9780240058899, "timesteps_since_restore": 245000, "iterations_since_restore": 123}
{"episode_reward_max": 636.0, "episode_reward_min": 411.0, "episode_reward_mean": 525.07, "episode_len_mean": 1000.0, "episodes_this_iter": 1, "policy_reward_mean": {"agent-0": 115.06, "agent-1": 100.85, "agent-2": 99.39, "agent-3": 91.23, "agent-4": 118.54}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 247000, "num_steps_sampled": 247000, "wait_time_ms": 8.541, "apply_time_ms": 8.176, "dispatch_time_ms": 25.689, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 247000, "episodes_total": 243, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-54-20", "timestamp": 1606319660, "training_iteration": 124, "time_this_iter_s": 7.170481204986572, "time_total_s": 929.1485052108765, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def87fd0>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def93160>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 929.1485052108765, "timesteps_since_restore": 247000, "iterations_since_restore": 124}
{"episode_reward_max": 636.0, "episode_reward_min": 411.0, "episode_reward_mean": 525.63, "episode_len_mean": 1000.0, "episodes_this_iter": 4, "policy_reward_mean": {"agent-0": 115.7, "agent-1": 100.72, "agent-2": 99.98, "agent-3": 90.64, "agent-4": 118.59}, "custom_metrics": {}, "num_metric_batches_dropped": 0, "info": {"num_steps_trained": 249000, "num_steps_sampled": 249000, "wait_time_ms": 5.337, "apply_time_ms": 6.708, "dispatch_time_ms": 23.365, "learner": {}}, "timesteps_this_iter": 2000, "done": false, "timesteps_total": 249000, "episodes_total": 247, "experiment_id": "3c53a64610424e268f2864e005a4de89", "date": "2020-11-25_16-54-27", "timestamp": 1606319667, "training_iteration": 125, "time_this_iter_s": 6.945062160491943, "time_total_s": 936.0935673713684, "pid": 17798, "hostname": "jupyter-cuda-tf2", "node_ip": "172.31.3.30", "config": {"monitor": false, "log_level": "INFO", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null}, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "squash_to_range": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 128, "lstm_use_prev_action_reward": false, "framestack": true, "dim": 84, "channel_major": false, "grayscale": false, "zero_mean": true, "custom_preprocessor": null, "custom_model": "conv_to_fc_net", "custom_options": {}}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "env_config": {"func_create": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def62390>", "env_name": "harvest_env", "run": "A3C"}, "env": "harvest_env", "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "num_workers": 6, "num_gpus": 0, "num_cpus_per_worker": 0.5, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "num_envs_per_worker": 1, "sample_batch_size": 10, "train_batch_size": 30000, "batch_mode": "truncate_episodes", "sample_async": true, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_evaluator_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "input": "sampler", "input_evaluation": null, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policy_graphs": {"agent-0": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-1": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-2": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-3": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}], "agent-4": ["<class 'ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph'>", "Box(15, 15, 3)", "Discrete(8)", {}]}, "policy_mapping_fn": "<ray.tune.suggest.variant_generator.function object at 0x7fa2def8d240>", "policies_to_train": null}, "use_pytorch": false, "lambda": 1.0, "grad_clip": 40.0, "lr": 0.0001, "lr_schedule": [[0, 0.00136], [20000000, 2.8e-05]], "vf_loss_coeff": 0.5, "entropy_coeff": -0.000687, "min_iter_time_s": 5}, "time_since_restore": 936.0935673713684, "timesteps_since_restore": 249000, "iterations_since_restore": 125}
