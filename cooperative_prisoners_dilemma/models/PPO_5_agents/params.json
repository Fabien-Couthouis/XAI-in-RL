{
  "batch_mode": "truncate_episodes",
  "clip_param": 0.3,
  "entropy_coeff": 0.001,
  "entropy_coeff_schedule": null,
  "env": "prisoner_dilemma",
  "env_config": {
    "num_players": 5,
    "num_repetitions": 10
  },
  "grad_clip": null,
  "kl_coeff": 0.2,
  "kl_target": 0.01,
  "lambda": 1.0,
  "lr": 5e-05,
  "lr_schedule": null,
  "model": {
    "vf_share_layers": false
  },
  "multiagent": {
    "policies": {
      "agent-0": [
        null,
        "Box(0.0, inf, (6,), float32)",
        "Discrete(6)",
        {
          "agent_id": "agent-0"
        }
      ],
      "agent-1": [
        null,
        "Box(0.0, inf, (6,), float32)",
        "Discrete(6)",
        {
          "agent_id": "agent-1"
        }
      ],
      "agent-2": [
        null,
        "Box(0.0, inf, (6,), float32)",
        "Discrete(6)",
        {
          "agent_id": "agent-2"
        }
      ],
      "agent-3": [
        null,
        "Box(0.0, inf, (6,), float32)",
        "Discrete(6)",
        {
          "agent_id": "agent-3"
        }
      ],
      "agent-4": [
        null,
        "Box(0.0, inf, (6,), float32)",
        "Discrete(6)",
        {
          "agent_id": "agent-4"
        }
      ]
    },
    "policy_mapping_fn": "<function get_ppo_config.<locals>.<lambda> at 0x7efac1a814c0>"
  },
  "num_envs_per_worker": 10,
  "num_sgd_iter": 30,
  "num_workers": 8,
  "observation_filter": "NoFilter",
  "rollout_fragment_length": 200,
  "sgd_minibatch_size": 128,
  "shuffle_sequences": true,
  "train_batch_size": 2000,
  "use_critic": true,
  "use_gae": true,
  "vf_clip_param": 10.0,
  "vf_loss_coeff": 1.0
}